{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    " # TP 6: Apprentissage profond(Deep learning)\n",
    " ## TP 6.4  : Optimisation solution naive\n",
    " \n",
    "- Régularisation :  Dropout\n",
    "- Normalisation \n",
    "    - Inputs\n",
    "    - les autres couches (batch Normalisation: avant ou après l'activation)\n",
    "- Optimiseurs: \n",
    "    - RMSProp, Adam, SGD, \n",
    "- Hyperparameter tuning : \n",
    "    - learning_rate\n",
    "    - \\#couches\n",
    "    - \\#neurones par couche\n",
    "    - taille du mini batch \n",
    "- ...\n",
    "# Exercice\n",
    "Trouver le meilleur modèle pour les données  de \"smoking\"\n",
    "Le programme doit tester les différentes configurations (et hyperparamètres).\n",
    "\n",
    "Visiter le site keras ou tensorflow pour vérifier la maniène d'utiliser ces différents paramètres\n",
    "\n",
    "PS : comparer aussi avec les modèles classiques : (KNN, Randomforest, ...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-13T08:14:55.293473300Z",
     "start_time": "2023-12-13T08:14:54.889842800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-13T08:14:55.441788800Z",
     "start_time": "2023-12-13T08:14:54.905139900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lecture du dataset n permet de limiter le nombre de lignes à lire\n",
    "# Pour faciliter les tests\n",
    "\n",
    "def load_data(n):\n",
    "    data = pd.read_csv('../../data/train.csv')\n",
    "    return data[0:n]\n",
    "\n",
    "def select_variables(data):\n",
    "    data.dropna(axis=0, inplace=True)\n",
    "    y = data['smoking'] # récupérer la colonne survived et la mettre dans y\n",
    "    # récuperer le reste des données dans X utiliser la fonction titanic.drop ???, ??? )\n",
    "    X = data.drop('smoking', axis=1)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-13T08:14:55.529782900Z",
     "start_time": "2023-12-13T08:14:54.921808400Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-13T08:14:55.617135300Z",
     "start_time": "2023-12-13T08:14:54.938558800Z"
    }
   },
   "outputs": [],
   "source": [
    "## On peut utiliser une simple normalisation (x-mu)/ecart type)\n",
    "def normaliser(X_train, X_test):\n",
    "    mean = X_train.mean()\n",
    "    std  = X_train.std()\n",
    "    X_train = (X_train - mean) / std\n",
    "    X_test  = (X_test  - mean) / std\n",
    "\n",
    "    return X_train, X_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition du modèle \n",
    "avec prise d'un nombre de couches et nombre de neurones variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-13T08:14:55.654096600Z",
     "start_time": "2023-12-13T08:14:54.957589100Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(nb_layers, nb_units):\n",
    "    m = X_train.shape[1]\n",
    "    model = tf.keras.Sequential ()\n",
    "    model.add(tf.keras.layers.Input(m, name=\"InputLayer\"))\n",
    "    for l in range(nb_layers):\n",
    "        model.add(tf.keras.layers.Dense(nb_units,name='layer'+str(l)))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Activation('relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation = 'sigmoid',name='output'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-13T08:14:55.689633400Z",
     "start_time": "2023-12-13T08:14:54.969379900Z"
    }
   },
   "outputs": [],
   "source": [
    "#Compiler le modèle\n",
    "#Optimiserer: SGD, AdamW, adadelta, ...\n",
    "def compiler(model,optimizer,loss,metrics):\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss= loss,\n",
    "                  metrics=[metrics])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Entrainement du modèle (Model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-13T08:14:55.690644100Z",
     "start_time": "2023-12-13T08:14:54.989876400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Entrainement du modele\n",
    "def train(model, X_train, y_train,epochs,batch_size):\n",
    "    history  = model.fit(X_train, \n",
    "                     y_train, \n",
    "                     epochs=epochs, \n",
    "                     batch_size= batch_size, \n",
    "                     verbose=False,\n",
    "                     validation_data = (X_test, y_test))\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation des performances du modèle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-13T08:14:55.691633200Z",
     "start_time": "2023-12-13T08:14:54.998877200Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluer(model, X_test, y_test):\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return score\n",
    "\n",
    "#print('Test loss     :', score[0])\n",
    "#print('Test accuracy :', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-13T08:14:55.708279700Z",
     "start_time": "2023-12-13T08:14:55.021871900Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualiser_confusion(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Get class labels\n",
    "    y_classes = np.argmax(y_pred, axis=-1)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_classes)\n",
    "    #disp= ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "    sns.heatmap(cm, annot=True, annot_kws={\"size\": 12}) # font size\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-13T08:14:55.803515100Z",
     "start_time": "2023-12-13T08:14:55.033887Z"
    }
   },
   "outputs": [],
   "source": [
    "# Préparation ds données\n",
    "# le -1 du load_data(-1) veut dire on prend toutes les lignes \n",
    "data=load_data(-1) \n",
    "# sélectionner les variables\n",
    "X,y = select_variables(data)\n",
    "X_train, X_test, y_train, y_test = split_data(X,y)\n",
    "X_train, X_test = normaliser(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-13T08:14:55.687635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Baran\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Baran\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Baran\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Baran\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "nb_layer 1 nb_units 16\n",
      "optimiseur Adam Test accuracy  epoch   : 10 batch 16 0.7682019472122192\n",
      "nb_layer 1 nb_units 16\n",
      "optimiseur Adam Test accuracy  epoch   : 10 batch 32 0.7689868211746216\n",
      "nb_layer 1 nb_units 16\n",
      "optimiseur Adam Test accuracy  epoch   : 50 batch 16 0.7689554691314697\n"
     ]
    }
   ],
   "source": [
    "history=[]\n",
    "loss='BinaryCrossentropy'\n",
    "metrics='accuracy'\n",
    "nb_layers=[1,2,4,6]\n",
    "nb_units=[16, 32]\n",
    "epochs=[10,50, 100]\n",
    "batch_size=[16, 32]\n",
    "optimizers = ['Adam', 'RMSprop', 'SGD', 'Adamax']\n",
    "\n",
    "best_model=0\n",
    "\n",
    "for l in nb_layers:\n",
    "    for u in nb_units:\n",
    "        model = build_model(l,u)\n",
    "        for optimize in optimizers:\n",
    "            for ep in epochs:\n",
    "                for batch in batch_size:\n",
    "                    model = compiler(model,optimize,loss,metrics)\n",
    "                    model,history = train(model, X_train, y_train,ep,batch)\n",
    "                    score = evaluer(model, X_test, y_test)\n",
    "                    print('nb_layer',l, 'nb_units' ,u)\n",
    "                    print('optimiseur',optimize,'Test accuracy  epoch   :',ep, 'batch', batch, score[1])\n",
    "                    if  score[1] > best_model:\n",
    "                        best_model = score[1]\n",
    "                        best_param_model = {\"#layers\":l,\"#units\": u, \"ep\":ep, \"batch\":batch, \"optimize\":optimize}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Afficher les paramètres du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "best_param_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "best_param_model[\"#layers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Play with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "## sur les données de Text (X_test, y_test)\n",
    "model = build_model(best_param_model[\"#layers\"],best_param_model[\"#units\"])  \n",
    "model = compiler(model,best_param_model[\"optimize\"],loss,metrics)\n",
    "model,history = train(model, X_train, y_train,best_param_model[\"ep\"],best_param_model[\"batch\"])\n",
    "score = evaluer(model, X_test, y_test)\n",
    "print('Test loss     :', score[0])\n",
    "print('Test accuracy :', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print('Test loss     :', score[0])\n",
    "print('Test accuracy :', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
