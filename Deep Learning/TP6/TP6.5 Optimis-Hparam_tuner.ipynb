{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  TP 6.5 Optimisation basée sur des tuners\n",
    "\n",
    "## Optimisation basée sur Keras tuner . \n",
    "Le but est de ne pas teste toutes les solutions possibles (grid solution) (GridSearch). \n",
    "- for param1 :\n",
    "    -  for parm2:\n",
    "        - for parm3\n",
    "            - ...\n",
    "\n",
    "Le tuner propose des méthodes qui permettent d'accélérer la recherche de la meilleure solution. \n",
    "Il propose 4 tuners\n",
    "- RandomSearch Tuner\n",
    "- GridSearch Tuner\n",
    "- BayesianOptimization Tuner\n",
    "- Hyperband Tuner\n",
    "- Sklearn Tuner\n",
    "\n",
    "Il faut aller sur le site de keras (https://keras.io/api/keras_tuner/tuners/), pour comprendre ce que fait chacun de ces tuners (vous pourrez aussi le trouver sur tensorflow (https://www.tensorflow.org/tutorials/keras/keras_tuner).\n",
    "\n",
    "il faut installer, keras-tuner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-14T07:47:41.806859300Z",
     "start_time": "2023-12-14T07:47:41.686029900Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install keras-tuner\n",
    "# pip install tensorflow==2.3.0\n",
    "# pip install tensorflow-gpu==2.3.0\n",
    "# install keras \n",
    "# pip install keras==2.4.3\n",
    "# pip install keras-tuner\n",
    "# install pandas\n",
    "# pip install pandas\n",
    "# install sklearn\n",
    "# pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-14T07:47:41.900874Z",
     "start_time": "2023-12-14T07:47:41.700597Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt  ## le keras tuner \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-14T07:47:41.922374800Z",
     "start_time": "2023-12-14T07:47:41.717545800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lecture du dataset n permet de limiter le nombre de lignes à lire\n",
    "# Pour faciliter les tests\n",
    "\n",
    "def load_data(n):\n",
    "    data = pd.read_csv('../../data/train.csv')\n",
    "    return data[0:n]\n",
    "\n",
    "def select_variables(data):\n",
    "    data.dropna(axis=0, inplace=True)\n",
    "    y = data['smoking'] # récupérer la colonne survived et la mettre dans y\n",
    "    # récuperer le reste des données dans X utiliser la fonction titanic.drop ???, ??? )\n",
    "    X = data.drop('smoking', axis=1)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-14T07:47:41.938142700Z",
     "start_time": "2023-12-14T07:47:41.731461700Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (127404, 23) X_test.shape (31851, 23)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   id  age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n0   0   55         165          60       81.0             0.5   \n1   1   70         165          65       89.0             0.6   \n2   2   20         170          75       81.0             0.4   \n3   3   35         180          95      105.0             1.5   \n4   4   30         165          60       80.5             1.5   \n\n   eyesight(right)  hearing(left)  hearing(right)  systolic  ...  HDL  LDL  \\\n0              0.6              1               1       135  ...   40   75   \n1              0.7              2               2       146  ...   57  126   \n2              0.5              1               1       118  ...   45   93   \n3              1.2              1               1       131  ...   38  102   \n4              1.0              1               1       121  ...   44   93   \n\n   hemoglobin  Urine protein  serum creatinine  AST  ALT  Gtp  dental caries  \\\n0        16.5              1               1.0   22   25   27              0   \n1        16.2              1               1.1   27   23   37              1   \n2        17.4              1               0.8   27   31   53              0   \n3        15.9              1               1.0   20   27   30              1   \n4        15.4              1               0.8   19   13   17              0   \n\n   smoking  \n0        1  \n1        0  \n2        1  \n3        0  \n4        1  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>height(cm)</th>\n      <th>weight(kg)</th>\n      <th>waist(cm)</th>\n      <th>eyesight(left)</th>\n      <th>eyesight(right)</th>\n      <th>hearing(left)</th>\n      <th>hearing(right)</th>\n      <th>systolic</th>\n      <th>...</th>\n      <th>HDL</th>\n      <th>LDL</th>\n      <th>hemoglobin</th>\n      <th>Urine protein</th>\n      <th>serum creatinine</th>\n      <th>AST</th>\n      <th>ALT</th>\n      <th>Gtp</th>\n      <th>dental caries</th>\n      <th>smoking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>55</td>\n      <td>165</td>\n      <td>60</td>\n      <td>81.0</td>\n      <td>0.5</td>\n      <td>0.6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>135</td>\n      <td>...</td>\n      <td>40</td>\n      <td>75</td>\n      <td>16.5</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>22</td>\n      <td>25</td>\n      <td>27</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>70</td>\n      <td>165</td>\n      <td>65</td>\n      <td>89.0</td>\n      <td>0.6</td>\n      <td>0.7</td>\n      <td>2</td>\n      <td>2</td>\n      <td>146</td>\n      <td>...</td>\n      <td>57</td>\n      <td>126</td>\n      <td>16.2</td>\n      <td>1</td>\n      <td>1.1</td>\n      <td>27</td>\n      <td>23</td>\n      <td>37</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>20</td>\n      <td>170</td>\n      <td>75</td>\n      <td>81.0</td>\n      <td>0.4</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>118</td>\n      <td>...</td>\n      <td>45</td>\n      <td>93</td>\n      <td>17.4</td>\n      <td>1</td>\n      <td>0.8</td>\n      <td>27</td>\n      <td>31</td>\n      <td>53</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>35</td>\n      <td>180</td>\n      <td>95</td>\n      <td>105.0</td>\n      <td>1.5</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>131</td>\n      <td>...</td>\n      <td>38</td>\n      <td>102</td>\n      <td>15.9</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>20</td>\n      <td>27</td>\n      <td>30</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>30</td>\n      <td>165</td>\n      <td>60</td>\n      <td>80.5</td>\n      <td>1.5</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>121</td>\n      <td>...</td>\n      <td>44</td>\n      <td>93</td>\n      <td>15.4</td>\n      <td>1</td>\n      <td>0.8</td>\n      <td>19</td>\n      <td>13</td>\n      <td>17</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Préparation ds données\n",
    "# le -1 du load_data(-1) veut dire on prend toutes les lignes\n",
    "data=load_data(-1)\n",
    "# sélectionner les variables\n",
    "X,y = select_variables(data)\n",
    "X_train, X_test, y_train, y_test = split_data(X,y)\n",
    "print(\"X_train.shape\", X_train.shape, \"X_test.shape\", X_test.shape)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T07:47:42.021002900Z",
     "start_time": "2023-12-14T07:47:41.748883200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-14T07:47:42.026851700Z",
     "start_time": "2023-12-14T07:47:41.980267100Z"
    }
   },
   "outputs": [],
   "source": [
    "## On peut utiliser une simple normalisation (x-mu)/ecart type)\n",
    "def normaliser(X_train, X_test):\n",
    "    mean = X_train.mean()\n",
    "    std  = X_train.std()\n",
    "    X_train = (X_train - mean) / std\n",
    "    X_test  = (X_test  - mean) / std\n",
    "\n",
    "    return X_train, X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-14T07:47:42.261733100Z",
     "start_time": "2023-12-14T07:47:41.996000800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (127404, 23) X_test.shape (31851, 23)\n"
     ]
    }
   ],
   "source": [
    "# Préparation ds données\n",
    "# le -1 du load_data(-1) veut dire on prend toutes les lignes \n",
    "data=load_data(-1)\n",
    "# sélectionner les variables\n",
    "X,y = select_variables(data)\n",
    "X_train, X_test, y_train, y_test = split_data(X,y)\n",
    "X_train, X_test = normaliser(X_train, X_test)\n",
    "print(\"X_train.shape\", X_train.shape, \"X_test.shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition du modèle.\n",
    "Je vous propose deux options, j'ai une préférence pour la deuxième option car on peut modifier le nombre de couches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Option 1 - les hyperparamètres à l'extérieur du modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-14T07:47:42.277222200Z",
     "start_time": "2023-12-14T07:47:42.260307300Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(neurons, lr, activations, hp_optimizers,optimizers_dict ): # type des données et leur significations en entrée, neurones : nommbres de neuronnes int , lr : learning rate float, activations : fonction d'activation str, hp_optimizers : optimizers str, optimizers_dict : dictionnaire des optimizers\n",
    "    m = X_train.shape[1] # nombre de colonnes de X_train car c'est la taille de la couche d'entrée\n",
    "    model = tf.keras.Sequential () # modèle séquentiel ou initialisation de l'objet modèle\n",
    "    model.add(tf.keras.layers.Input(m,name=\"InputLayer\")) # couche d'entrée\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation=activations)) # couche cachée\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation=activations)) # couche cachée\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation = 'sigmoid',name='output')) # couche de sortie\n",
    "    # en gros on a construit un modèle avec 2 couches cachées de 16 neurones\n",
    "    model.compile(optimizer=optimizers_dict[hp_optimizers], \n",
    "                  loss=\"BinaryCrossentropy\", \n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "## Définir les différents paramètres à tester \n",
    "def build_model_opt1(hp):\n",
    "    neurons = hp.Int(\"units\", min_value=16, max_value=300, step=16)\n",
    "    lr = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2)\n",
    "    #p_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    activations=hp.Choice('activation',values=['tanh' ], default='tanh')\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-1)\n",
    "    \n",
    "    optimizers_dict = {\n",
    "        \"Adam\":    tf.keras.optimizers.legacy.Adamax(learning_rate=learning_rate),\n",
    "        \"Adamax\":  tf.keras.optimizers.legacy.Adamax(learning_rate=learning_rate),\n",
    "        \"SGD\":     tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate),\n",
    "        \"Adagrad\": tf.keras.optimizers.legacy.Adagrad(learning_rate=learning_rate)\n",
    "        }\n",
    "\n",
    "    hp_optimizers = hp.Choice('optimizer', values=[\"Adam\",\"Adamax\", \"SGD\", \"Adagrad\"])\n",
    "    \n",
    "    model = create_model(\n",
    "        neurons=neurons, lr=lr, activations=activations, hp_optimizers=hp_optimizers, optimizers_dict=optimizers_dict \n",
    "    )\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Option 2: les hyperparamètres sont définis dans le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-14T07:47:42.331115100Z",
     "start_time": "2023-12-14T07:47:42.280471800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<keras.src.engine.sequential.Sequential at 0x1be2203b550>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model_opt2(hp): # hp : hyperparamètres, type de hp : kt.HyperParameters\n",
    "    model = tf.keras.Sequential() # modèle séquentiel ou initialisation de l'objet modèle\n",
    "    # Tune the number of layers.\n",
    "    m = X_train.shape[1] # colonnes de x_train\n",
    "    \n",
    "    model = tf.keras.Sequential () # modèle séquentiel ou initialisation de l'objet modèle\n",
    "    # couche d'entrée\n",
    "    model.add(tf.keras.layers.Input(m,name=\"InputLayer\")) # couche d'entrée\n",
    "    # les;couches cachées\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 5)): # permet de choisir un nombre de couches entre entre 1 et i=5\n",
    "        model.add(\n",
    "            tf.keras.layers.Dense( \n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=16, max_value=200, step=16),# permet de choisir le nombre de neurones entre 16 et 200\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),# permet de choisir la fonction d'activation entre relu et tanh\n",
    "                )\n",
    "        )\n",
    "        # la couche de sortie \n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\")) # sigmoid car c'est un problème de classification binaire, sinon une regression on aurait mis linear, multi-class classification on aurait mis softmax\n",
    "    \n",
    "    # Liste hyperparameètres à optimiser   \n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-1) #\n",
    "    optimizers_dict = {\n",
    "        \"Adam\":    tf.keras.optimizers.legacy.Adamax(learning_rate=learning_rate),\n",
    "        \"Adamax\":  tf.keras.optimizers.legacy.Adamax(learning_rate=learning_rate),\n",
    "        \"SGD\":     tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate),\n",
    "        \"Adagrad\": tf.keras.optimizers.legacy.Adagrad(learning_rate=learning_rate)\n",
    "        }\n",
    "\n",
    "    hp_optimizers = hp.Choice('optimizer', values=[\"Adam\",\"Adamax\", \"SGD\", \"Adagrad\"])\n",
    "    \n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizers_dict[hp_optimizers],\n",
    "        loss=\"BinaryCrossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "build_model_opt2(kt.HyperParameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix du tuner ainsi que ses paramètres. \n",
    "Conseil : visiter le site pour visualiser les différents paramètres du tuner (https://keras.io/api/keras_tuner/tuners/base_tuner/#tuner-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-14T07:47:42.400943700Z",
     "start_time": "2023-12-14T07:47:42.326270900Z"
    }
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 44: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_2668\\1191286105.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m#tuner : Gridsearch, RandomSearch, BayesianOptimization, Hyperband\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m tuner = kt.BayesianOptimization(\n\u001B[0m\u001B[0;32m      3\u001B[0m     \u001B[0mbuild_model_opt2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mobjective\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'val_accuracy'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mmax_trials\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m16\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\tuners\\bayesian.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, hypermodel, objective, max_trials, num_initial_points, alpha, beta, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001B[0m\n\u001B[0;32m    392\u001B[0m             \u001B[0mmax_consecutive_failed_trials\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmax_consecutive_failed_trials\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    393\u001B[0m         )\n\u001B[1;32m--> 394\u001B[1;33m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moracle\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moracle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhypermodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mhypermodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    395\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001B[0m\n\u001B[0;32m    120\u001B[0m             )\n\u001B[0;32m    121\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 122\u001B[1;33m         super().__init__(\n\u001B[0m\u001B[0;32m    123\u001B[0m             \u001B[0moracle\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moracle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    124\u001B[0m             \u001B[0mhypermodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mhypermodel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    120\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0moverwrite\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mbackend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mproject_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 121\u001B[1;33m             \u001B[0mbackend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrmtree\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mproject_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    122\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    123\u001B[0m         \u001B[1;31m# To support tuning distribution.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\backend\\io.py\u001B[0m in \u001B[0;36mrmtree\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m     35\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mtf\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mshutil\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrmtree\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 37\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrmtree\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     38\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001B[0m in \u001B[0;36mdelete_recursively_v2\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m    674\u001B[0m     \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mOpError\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIf\u001B[0m \u001B[0mthe\u001B[0m \u001B[0moperation\u001B[0m \u001B[0mfails\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    675\u001B[0m   \"\"\"\n\u001B[1;32m--> 676\u001B[1;33m   \u001B[0m_pywrap_file_io\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDeleteRecursively\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcompat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath_to_bytes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    677\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    678\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mUnicodeDecodeError\u001B[0m: 'utf-8' codec can't decode byte 0xe9 in position 44: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "#tuner : Gridsearch, RandomSearch, BayesianOptimization, Hyperband\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_model_opt2,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=16,\n",
    "    overwrite=True,\n",
    "    directory=\"TuneData\",\n",
    "    project_name=\"tuning_BN\",)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.357159600Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "tuner = kt.Hyperband(\n",
    "    build_model_opt2,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=16,\n",
    "    factor=3,\n",
    "    directory='TuneData',\n",
    "    project_name='tuning_hyperband')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualiser les différents paramètres à tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.358156700Z"
    }
   },
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lancer la méthode search du tuner avec ses paramètres pour rechercher les best paramètres\n",
    "Avant de lancer la méthode search on peut aussi lui demander de stopper la recherche si les résultats ne s'améliorent pas, ceci grace à (f.keras.callbacks.EarlyStopping) (https://keras.io/api/callbacks/early_stopping/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.360230900Z"
    }
   },
   "outputs": [],
   "source": [
    "## cette méthode est utile elle permet de stopper la recherche de solutions \n",
    "## quand l'erreur (ou la précision, ou ..), variable monitor= la loss, ne s'améliore pas \n",
    "## au bout de patience=5 epochs\n",
    "\n",
    "early_stoping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5,\n",
    "    restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.362285500Z"
    }
   },
   "outputs": [],
   "source": [
    "tuner.search(X_train, y_train, epochs=32, validation_data=(X_test, y_test), batch_size=32, callbacks=[early_stoping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.363319600Z"
    }
   },
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Récupérer (get) les meilleurs paramètres, le meilleur modèle, ....\n",
    "(https://keras.io/api/keras_tuner/tuners/#the-base-tuner-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.364523800Z"
    }
   },
   "outputs": [],
   "source": [
    "# le meilleur modèle est stocké en position [0] du get_best_model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Les best paramètres\n",
    "best_hps=tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "print(\"best #layers : \",best_hps.get('num_layers'))\n",
    "print(\"best learning_rate : \",best_hps.get('learning_rate'))\n",
    "print(\"best activation : \",best_hps.get('activation'))\n",
    "print(\"best optimizer : \",best_hps.get('optimizer'))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Comment utiliser le meilleur modèle\n",
    "- Le meilleur modèle \"best_model = tuner.get_best_models()\" vient avec le mdèle de neurones déjà entrainé, les paramètres du modèle( W et les b) sont déjà appris. C'est ce que l'on nomme un \"checkpoint\". Ce modèle est à utiliser directement dans la phase d'évaluation(prédiction)\n",
    "- Sinon, le best_hps=tuner.get_best_hyperparameters()[0], lui récupère les meilleurs paramètres. Vous pourrez repartir de ces paramètres pour entrainer le modèle. (solution préconisée)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.367493400Z"
    }
   },
   "outputs": [],
   "source": [
    "## Sélectionner les meileurs hyperparamètres du modèle\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Réentrainer le modèle avec ls nouveaux hyperparamètres\n",
    "history = best_model.fit(X_train, y_train, epochs=50, validation_data = (X_test, y_test), \n",
    "                         batch_size=32, \n",
    "                         verbose=False\n",
    "                         callbacks=[early_stoping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.368578300Z"
    }
   },
   "outputs": [],
   "source": [
    "# AH quelle est la meilleure epoch ?? \n",
    "# Réupérer la best epoch\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.370586Z"
    }
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.371649400Z"
    }
   },
   "outputs": [],
   "source": [
    "## On peut aussi sélectionner les meileurs hyperparamètres\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# on réentraine le modèle avec ls nouveaux hyperparamètres\n",
    "best_model.fit(X_train, y_train, epochs=best_epoch, validation_data = (X_test, y_test), \n",
    "                         batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.373727600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utilisation du best model\n",
    "score = best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.373727600Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"la loss\",score[0], \"l'accracy\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.374735600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(history.history).plot(figsize=(15,8))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.375736500Z"
    }
   },
   "outputs": [],
   "source": [
    "y_prob = best_model.predict(X_test)\n",
    "y_classes = y_prob.argmax(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.376735300Z"
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix = tf.math.confusion_matrix(y_test, y_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-14T07:47:42.376735300Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sb    \n",
    "class_names=[0,1]\n",
    "# ax = plt.figure(figsize=(8, 6))\n",
    "fig = sb.heatmap(confusion_matrix,  cmap='Greens')  \n",
    "\n",
    "# labels, title and ticks\n",
    "fig.set_xlabel('Predicted labels')\n",
    "fig.set_ylabel('True labels')\n",
    "fig.set_title('Confusion Matrix')\n",
    "fig.xaxis.set_ticklabels(class_names) \n",
    "fig.yaxis.set_ticklabels(class_names)\n",
    "fig.figure.set_size_inches(5, 5)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
