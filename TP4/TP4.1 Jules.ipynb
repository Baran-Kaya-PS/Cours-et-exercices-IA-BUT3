{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MachineLearnia/Python-Machine-Learning/blob/master/21%20-%20Sklearn%20%3A%20Model%20Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4jcmYk2hRou"
   },
   "source": [
    "# TP4   Evaluation des performances - Sélection de Modèles \n",
    "# TP 4.1 : Prise en main de l'évaluation \n",
    "**IMPRTANT** : \n",
    "L'évaluation des perfomances d'un algotrithme d'apprentissage ne se fait JAMAIS sur les données utilisées pour l'apprentissage.\n",
    "Elle se fait sur des données que l'algorithme (la méthode) n'a jamais vues auparavant. \n",
    "\n",
    "On parle alors de <span style=\"color:green\"> ``train_set``</span> (ensemble d'entrainement) et <span style=\"color:green\"> ``test_set``</span> (ensemble de test)\n",
    "*SkLearn* nous offre la possibilité de couper un ensemble de données en $train\\_set$ et $test\\_set$ grace à <br>\n",
    "``from sklearn.model_selection import train_test_split``\n",
    "\n",
    "Sklearn propose aussi plusieurs  [datasets](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets), on peut les lire directement à partir du module ``from sklearn.datasets import ......?``. Importer le dataset à utiliser.\n",
    "\n",
    "### Métriques d'évaluation des modèles\n",
    "- **Problèmes de classification** : Accuracy, Précision (precision), Confusion Matrix (matrice de confusion)\n",
    "\n",
    "- **Problèmes de régression** : Mean Absolute Error (Erreur absolue moyenne), Mean Squared Error (erreur quadratique moyenne), Root Mean Squared Error Racine de erreur quadratique moyenne)\n",
    "\n",
    "<span style=\"color:green\"> **from sklearn.metrics import accuracy_score, ...** </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B7NxFWYohM7X",
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.564326100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris, load_diabetes #IRIS est un dataset comportant des images des IRIS (déjà vu en 1ère année)\n",
    "from sklearn.preprocessing import  RobustScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectifs du TP  :  \n",
    "- Utilisation de différents algorithmes d'apprentissage sur deux cas \n",
    "- cas 1 : Entrainement et test sur les mêmes données\n",
    "- cas 2 : Entrainement sur des données d'apprentissage et test dsur des données de test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas 1 : Entrainement et test sur les mêmes données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.621691600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Le dataset Titanic  \n",
    "\n",
    "import pandas as pd \n",
    "titanic = pd.read_csv('./data/titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T06:33:44.720177200Z",
     "start_time": "2023-10-11T06:33:44.678283900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  Sex   Age\n",
      "0         3    0  22.0\n",
      "1         1    1  38.0\n",
      "2         3    1  26.0\n",
      "3         1    1  35.0\n",
      "4         3    0  35.0\n",
      "..      ...  ...   ...\n",
      "885       3    1  39.0\n",
      "886       2    0  27.0\n",
      "887       1    1  19.0\n",
      "889       1    0  26.0\n",
      "890       3    0  32.0\n",
      "\n",
      "[714 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "titanic = titanic[['Survived', 'Pclass', 'Sex', 'Age']]\n",
    "X_features = ['Pclass', 'Sex', 'Age']\n",
    "titanic.dropna(axis=0, inplace=True)\n",
    "titanic['Sex'].replace(['male', 'female'], [0, 1], inplace=True)\n",
    "titanic.head()\n",
    "X_train = titanic[X_features]\n",
    "y_train = titanic['Survived']\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Régression logistique ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.577321500Z"
    }
   },
   "outputs": [],
   "source": [
    "## On utilise une regresion logistique\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# training\n",
    "modelLogistic = LogisticRegression()\n",
    "\n",
    "modelLogistic.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "logPred = modelLogistic.predict(X_train)\n",
    "\n",
    "\n",
    "# test sur test_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### KNN k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sXcL7swXiGEH",
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.582326Z"
    }
   },
   "outputs": [],
   "source": [
    "# On utiisera un KNN k plus proches voisins\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# On prend un modèle avec un voisin k=3\n",
    "model_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "model_knn.fit(X_train, y_train)\n",
    "# Train \n",
    "\n",
    "knn_pred = model_knn.predict(X_train)\n",
    "# predict sur X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation des performances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.586325900Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T06:33:43.594656500Z",
     "start_time": "2023-10-11T06:33:43.590320Z"
    }
   },
   "outputs": [],
   "source": [
    "print('--------- KNN 3 voisins --------------')\n",
    "print('Accuracy sur le test ', accuracy_score(y_train, knn_pred))\n",
    "print('precision sur le test :', precision_score(y_train, knn_pred))\n",
    "print('F1  sur le test :', f1_score(y_train, knn_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.593505300Z"
    }
   },
   "outputs": [],
   "source": [
    "print('--------- Logistic Regression --------------')\n",
    "print('Accuracy sur le test ', accuracy_score(y_train, logPred))\n",
    "print('precision sur le test :', precision_score(y_train, logPred))\n",
    "print('F1  sur le test :', f1_score(y_train, logPred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas 2 : Eval sur des données de test.  (Train Test Split)\n",
    "1) Entraînement et test sur les mêmes données\n",
    "    - Récompense les modèles trop complexes qui \"surajoutent\" les données d'apprentissage et ne se généralisent pas nécessairement.\n",
    "2) Séparation Training/test\n",
    "    - Diviser l'ensemble de données en deux parties, de sorte que le modèle puisse être entraîné et testé sur des données différentes.\n",
    "    - Meilleure estimation des performances hors échantillon\n",
    "3) Validation croisée K-fold\n",
    "    - Création systématique de \"K\" folds (divisions) training/test et calcul de la moyenne des résultats.\n",
    "    - Meilleure estimation des performances hors échantillon\n",
    "    - S'exécute \"K\" fois plus lentement que le train/test strategie\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "btBmZOGRhwa7"
   },
   "source": [
    "### from sklearn.model_selection import train_test_split\n",
    "SKlearn propose la méthode train_test_split dans le module sklearn.model_selection (penser à aller visiter ce module) **from sklearn.model_selection import train_test_split**<br>\n",
    "le code :  *train_test_split(X, y, test_size=0.2, random_state=5)*\n",
    "les paramètres de train_test_split:\n",
    "- (X et y données du dataset (X les features) et y (le resulltat souhaité))\n",
    "- test_size est le pourcentage de données de test ici 0.2 (20%), \n",
    "- random_state ? pour indiquer que les données soient mélangées aléatoirement pour éviter les biais \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-2DS06RUhuvT",
    "ExecuteTime": {
     "end_time": "2023-10-11T06:33:43.597761700Z",
     "start_time": "2023-10-11T06:33:43.596725800Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliter les données  (20% test et le reste training) ?\n",
    "- SPliter le dataset et vérifier la dimension de vos données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "jkESrHJ0h2RJ",
    "outputId": "d278cc06-7b3f-4e7f-9b07-451525a5fa6a",
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.598748200Z"
    }
   },
   "outputs": [],
   "source": [
    "# les paramètres de train_test_split (X et y données du dataset (X les fatures) et Y (le resulltat souhaité))\n",
    "# test_sizet est le pourcentage de données de test ici 0.2 (20%), random_state ? pour indiquer q\n",
    "# ue les données soient mélangées aléatoirement pour  éviter les biaias \n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic[X_features], titanic[\"Survived\"], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.601711100Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Régression logistique ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.603717400Z"
    }
   },
   "outputs": [],
   "source": [
    "## On utilise une regresion logistique\n",
    "#le modèle\n",
    "\n",
    "\n",
    "# training\n",
    "m\n",
    "\n",
    "# test sur test_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN k=3 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.605133900Z"
    }
   },
   "outputs": [],
   "source": [
    "# On utiisera un KNN k plus proches voisins\n",
    "\n",
    "# On prend un modèle avec un voisin k=3\n",
    "\n",
    "# training \n",
    "\n",
    "\n",
    "# prediction sur les données de test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.606503300Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparer les performance des différents modèles pour les deux cas étudiés?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.607514200Z"
    }
   },
   "outputs": [],
   "source": [
    "print ('**** Performances Logistique régression ****')\n",
    "print('Accuracy sur le training :', ..... ))\n",
    "print('precision sur le traing :', .... )\n",
    "print('F1  sur le training :', )\n",
    "print()        \n",
    "print('Accuracy sur le test :', )\n",
    "print('precision sur le test :', )\n",
    "print('F1  sur le test :', )\n",
    "print()   \n",
    "print() \n",
    "print ('**** Performances KNN ****')  \n",
    "print('Accuracy sur le training :', )\n",
    "print('precision sur le traing :', )\n",
    "print('F1  sur le training :', )\n",
    "print() \n",
    "print('Accuracy sur le test :', )\n",
    "print('precision sur le test :', ))\n",
    "print('F1  sur le test :',    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de confusion\n",
    "La matrice de confusion est un autre moyen qui permeet de visualiser es résultats. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.609519700Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.610516400Z"
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_lg, labels=model_lg.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.612848500Z"
    }
   },
   "outputs": [],
   "source": [
    "#m=confusion_matrix(y_test, y_pred_lg)\n",
    "m = confusion_matrix(y_test, y_pred_lg, labels=model_lg.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=m, display_labels=model_lg.classes_)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1:\n",
    "Reprendre le même travail  (démarche) pour le cas d'une régression linéaire. Les métriques sont différentes. Comparer deux modèles d'apprentissage, par exemple un LinearRegression et un Ridge avec (alpha=.5)\n",
    "\n",
    " On fera juste le cas 2, qui représente la démarche normale d'évaluation d'un modèle d'apprentissage \n",
    "- Lire les données du fichier house.txt\n",
    "- Spliter les données (attention le fichier houses, comporte tous les *features* et les *labels*. Il faut les séparer.\n",
    "- choisir le (s) modèle(s) de regression, entrainer-le(s), puis tester.\n",
    "- afficher les scores des performznces : MAE, MSE, RMSE et R2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.614355800Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"../data/houses.txt\", delimiter=',', skiprows=1)\n",
    "# récupérer toutes les lgnes data[:, et les 4 premières colonnes data[ ..,:4]\n",
    "X_train = data[:,:4]\n",
    "y_train = data[:,4]\n",
    "X_features = ['size','bedrooms','floors','age']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix du modèle, entrainement, test ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T06:33:43.703248100Z",
     "start_time": "2023-10-11T06:33:43.615573900Z"
    }
   },
   "outputs": [],
   "source": [
    "# import model\n",
    "\n",
    "# instantiate\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "\n",
    "# test \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation des performances ?\n",
    "Utiliser les 4 measures étudiées au cours : r2_score, mean_absolute_error, rmse, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.616584200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.618597900Z"
    }
   },
   "outputs": [],
   "source": [
    "print('MAE :', )\n",
    "print('MSE :', )\n",
    "print('RMSE :', )\n",
    "print('R2 score :', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2:\n",
    "Reprendre le même travail (démarche) pour une classification multiclasses, prendre le dataset iris.\n",
    "Attention : à la régression logistique (vérifier le paramètrage) et aux métriques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-11T06:33:43.620683800Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPnB01zyw2z4FoQV1MhdR1V",
   "include_colab_link": true,
   "name": "Untitled17.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
