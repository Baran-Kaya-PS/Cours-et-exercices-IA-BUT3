{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:21.608909400Z",
     "start_time": "2023-11-23T09:50:21.231627100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nIUT Paul Sabatier\\nDépartement Informatique\\nBUT3 - R5.08 (AGED)\\n2023-2024\\nContrôle 1\\nDurée 2h20\\nLe contrôle comporte deux parties : un QCM (20 minutes) + un Exercice\\nDocuments autorisés\\nExercice à réaliser de préférence sur un ordinateur. Le fichier produit doit être téléversé sur\\nMoodle (dans le dossier Contrôle1).\\nExercice :\\nOn souhaite mettre en place un modèle de machine learning capable de prédire le statut\\ntabagique (fumeur ou non fumeur) d\\'un patient à partir d\\'informations sur divers autres\\nindicateurs de santé et autre.\\nLes indicateurs sont listés dans le tableau ci-dessous.\\nLe dataset est sur Moodle (train.new.csv.zip), il comporte une centaine de milliers de\\ndonnées vous pourrez l\\'exploiter comme vous le souhaitez.\\nQuestion 1 :\\nOn vous demande de proposer d’indiquer le (vôtre) modèle d\\'apprentissage le plus optimal.\\nVotre solution doit au moins tester trois algorithmes différents (trois modèles de machine\\nlearning).\\nIl sera tenu compte dans l\\'évaluation de toute la procédure que vous avez choisie pour :\\n- la préparation des données\\n- le choix des variables importantes/utiles (avec des visualisations de données\\nappropriées pour effectuer ces choix)\\n- le choix des modèles d\\'apprentissage\\n- la méthodologie d\\'évaluation\\n- le rendu des résultats des évaluations (les performances) des différentes solutions.\\nLe dataset comporte les données suivantes :\\nage âge :\\nsex sexe\\nheight(cm) taille(cm)\\ncountry Pays\\nweight(kg) poids(kg)\\nwaist(cm) : Waist circumference length taille(cm) : Tour de taille longueur\\neyesight(left) vue (gauche)\\neyesight(right) vue (droite)\\nhearing(left) ouïe(gauche)\\nhearing(right) ouïe(droite)\\nsystolic : Blood pressure systolique : Pression artérielle\\nrelaxation : Blood pressure relaxation : tension artérielle\\nfasting blood sugar glycémie à jeun\\nCholesterol : total Cholestérol : total\\ntriglyceride triglycérides\\nHDL : cholesterol type HDL : type de cholestérol\\nLDL : cholesterol type LDL : type de cholestérol\\nhemoglobin hémoglobine\\nUrine protein Protéines urinaires\\nserum creatinine créatinine sérique\\nAST : glutamic oxaloacetic transaminase type AST : type de transaminase glutamique\\noxaloacétique\\nALT : glutamic oxaloacetic transaminase type ALT : transaminase glutamique oxaloacétique\\ntype\\nGtp : γ-GTP Gtp : γ-GTP\\ndental caries caries dentaires\\nsmoking tabagisme\\nQuestion 2 :\\nDonner la valeur prédite par votre algorithme optimal pour le patient ayant les indicateurs\\nsuivants :\\nId, 1891\\nage, 35\\nsex, M\\ncountry, usa\\nheight(cm), 185\\nweight(kg), 80\\nwaist(cm), 84.0\\neyesight(left), 1.2\\neyesight(right), 0.9\\nhearing(left), 1\\nhearing(right), 1\\nsystolic 130\\nrelaxation, 70\\nfasting blood sugar, 99\\nCholesterol, 211\\ntriglyceride, 210\\nHDL, 41\\nLDL, 127\\nhemoglobin, 15.6\\nUrine protein, 1\\nserum creatinine, 1.3\\nAST, 22\\nALT, 13\\nGtp, 21\\ndental caries 0\\nValeurs en ligne pour copie/coller :\\n191 190 55 F usa 175 80 87.1 0.9 0.8 1 1 137\\n89 177 170 96 43 108 14.5 1 1.1 26 41 20 0\\nQuestion 3 (4pts) :\\nLe dataset a été modifié, plus précisément la colonne smoking (le statut tabagique) a été\\naffiné pour mieux séparer les statuts tabagiques certains de ceux qui ne le sont pas. Ainsi\\nau lieu d’avoir deux valeurs possibles (1 : fumeur, 0 : non fumeur), La colonne smoking\\n(statut tabagique) a été étendu à 3 valeurs possibles, de 0 à 2 (0: non fumeur, 1 : plutôt\\nfumeur, 2 : certainement fumeur).\\nLe nouveau fichier est : train.new.multi.csv.zip. Seule la colonne smoking a été modifiée.\\nProposer une solution (modèle d’apprentissage) permettant de prédire ce nouveau statut\\ntabagique en fonction des indicateurs de santé d’un patient.\\nQuelle est la classe prédite pour le patient suivant (les valeurs ci-dessous sont listées dans le\\nmême ordre que la liste du tableau ci-dessus.).:\\n481 60 M usa 160 65 78.0 0.8 0.7 1 1 118 62\\n97 154 88 37 100 12.6 1 0.5 23 14 9 0\\n\\nVoici le code que j\\'ai pu écrire pour un autre travail : \\n# # TP5.2 -  Exercice (Récap)\\n# On reprend le fichier titanic. La démarche qu\\'il faut suivre pour la mise en place d\\'un projet de machine learning est la suivante : \\n# - Analyse des données du Dataset\\n#   - Analayse de la forme :\\n#       - Vérifier la taille du Dataset X\\n#       - Identifier les variables et les labels et leurs types\\n#       - Visualiser quelques données\\n#       - Analyser les données manquantes\\n#       \\n#  - Pré-traitement des données\\n#     - Elimination des colonnes inutiles\\n#     - Traiter es valeurs manquantes\\n#     - Encoder les colonnes non numériques\\n#     - Selection de variables utiles \\n#     - Afficher (uniquement les courbes à deux dimensions, par exemple la colonne 4 `X[:, 3]`, en fonction de la colonne 3, `X[:, 2]`)\\n#     - Création des Train set et Test set \\n#     - Normaliser des données des différentes colonnes \\n# \\n# - Définition du modèle de machine learning adéquat à la tâche (données)\\n# - Evaluation et calcul de performances (ATTENTION Il faut choisir la bonne métrique).\\n# \\n# \\n# ## Questions \\n# En s\\'appuyant sur la démarche décrite ci-dessus, comparer les modèles dans les cas suivants :\\n# - donnéees normalisées versus non normalisées\\n# - données manquantes traitées versus non traitées\\n# sur les deux données normalisées et non normalisées et évaluation de leurs performances.\\n# - comparer différents (2 alogos d\\'apprentissage). <br>\\n# \\n# PS :\\n# *** ATTENTION n\\'oubiez pas de normaliser aussi les données de test. \\n# La normalisation des données ne peut se faire que sur les données d\\'apprentissage. \\n# <span style=\"color:red\"> Il ne faut jamais normaliser avant de spliter les données.\\n# Les données de test ne sont pas connues, un algo. d\\'apprentissage ne doit jamais utliser une quelconque donnée qui vient des données de test sinon **BIAIS*</span>\\n# \\n# <span style=\"color:green\"> La normalisatin doit donc utiliser le même modèle (```transformer```) que celui utilisé dans la phase d\\'apprentissage ET SURTOUT la même échelle.</span> \\n# \\n# Rappel : pour les données d\\'entrainement on uilise la méthode ```fit_tranform()```et pour les données de test, ```transform()```\\n# \\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport pandas as pd \\nfrom sklearn.preprocessing import LabelEncoder, LabelBinarizer, OrdinalEncoder, OneHotEncoder\\nfrom sklearn.impute import SimpleImputer, KNNImputer\\n# ### 1 Le dataset\\n# - Lecture du Dataset et Analyse des données\\ndef load_titanic() -> pd.DataFrame:\\n\\nLoad\\nthe\\ntitanic\\ndataset.\\nReturns:\\nDataFrame: the\\ntitanic\\ndataset.\\n\\ntitanic = pd.read_csv(\\'./data/titanic.csv\\')\\nreturn titanic\\n\\nraw_titanic_data = load_titanic()\\n# #### Coup d\\'oeil rapide sur le contenu .head()\\nraw_titanic_data.head(3)\\n# #### Vérification taille, type des données \\n# \\nraw_titanic_data.info()\\n# #### Types variables\\n# #### Analyse des données manquantes  \\n# - Combien de valeurs manquantes (selon l\\'objet renvoyé, pandas ou numpy)\\n# - On peut caculer le pourcentage de valeurs manquantes  *data.isnull().sum()/data.shape[0])* \\nraw_titanic_data.isna().sum()/raw_titanic_data.shape[0]*100\\n# #### Visualisation (Survived le label en fonction des variables)\\nsns.pairplot(raw_titanic_data, hue=\\'Survived\\')\\n# #### Matrice de correlation \\nsns.heatmap(raw_titanic_data.corr(), annot=True)\\n# ### 2. Pré-traitement des données \\n# #### Elimination colonnes inutiles\\n# - Utiliser uniquement \\'Survived\\', \\'Pclass\\', \\'Sex\\', \\'Age\\', \\'Fare\\'\\ntitanic = raw_titanic_data[[\\'Survived\\', \\'Pclass\\', \\'Sex\\', \\'Age\\', \\'Fare\\']]\\nX_features = [\"Pclass\", \"Sex\", \"Age\", \"Fare\"]\\ntitanic[\"Sex\"] = titanic[\\'Sex\\'].replace([\\'male\\', \\'female\\'], [0, 1])\\ntitanic.head(3)\\n\\n\\n# #### Traiter les valeurs manquantes\\n# - Deux cas : utiliser un imputer ou supprimer toutes les lignes vides\\n#Avant quoique ce soit on sépare les données en train et test\\nfrom sklearn.model_selection import train_test_split\\ntrain, test = train_test_split(titanic, test_size=0.2, random_state=42)\\n\\ntrain_without_nan = train.dropna()\\ntest_without_nan = test.dropna() #dropna supprime les lignes qui ont des valeurs manquantes\\nfrom sklearn.impute import SimpleImputer\\nimputer = SimpleImputer(strategy=\"mean\", missing_values=np.nan)\\nimputer.fit(train[X_features]) # le imputer sert a remplacer les valeurs manquantes par la moyenne\\ny_with_all_values = train[\"Survived\"]\\ny_test_with_all_values = test[\"Survived\"]\\ntrain_imputed = imputer.transform(train[X_features])\\ntest_imputed = imputer.transform(test[X_features])\\n\\n\\n# #### Encodage des données non numériques ?\\n#Pas besoin l\\'encodage des données non numériques car on a déjà fait le remplacement des valeurs sexes\\n# mais pour encoder on utilise la méthode LabelEncoder\\n# #### Normalisation \\n# Attention la normalisation à la normalisation des données de test.\\n#Normalisation des données\\nfrom sklearn.preprocessing import StandardScaler\\nscaler = StandardScaler()\\nscaler.fit(train_imputed)\\ntrain_scaled_imputed = scaler.transform(train_imputed)\\ntest_scaled_imputed = scaler.transform(test_imputed)\\n\\ntrain_scaled_imputed\\n# ### Pré-processing des données\\n\\n\\n# #### Visualisation de de queques données (normalisées et non non normalisées) ?\\nplt.scatter(range(0, len(train_scaled_imputed[:,2])), train_scaled_imputed[:,2])\\nplt.scatter(range(0,len(train[\"Age\"])), train[\"Age\"])\\nplt.title(\"Age\")\\n\\nplt.scatter(range(0, len(train_scaled_imputed[:,3])), train_scaled_imputed[:,3])\\nplt.scatter(range(0,len(train[\"Fare\"])), train[\"Fare\"])\\nplt.scatter(range(0, len(train_scaled_imputed[:,0])), train_scaled_imputed[:,0])\\nplt.scatter(range(0,len(train[\"Pclass\"])), train[\"Pclass\"])\\nplt.title(\"Pclass\")\\nplt.scatter(range(0, len(train_scaled_imputed[:,1])), train_scaled_imputed[:,1])\\nplt.scatter(range(0,len(train[\"Sex\"])), train[\"Sex\"])\\n\\n# ## Modélisation\\n#Modelisation\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nn=5\\nlog_reg = KNeighborsClassifier(n_neighbors=n)\\nlog_reg_naive = KNeighborsClassifier(n_neighbors=n)\\n# ### Entrainement\\nlog_reg_naive.fit(train_without_nan[X_features],train_without_nan[\"Survived\"]) # no préprocessing (pas de normalisation, pas de traitement des valeurs manquantes)\\nlog_reg.fit(train_scaled_imputed, y_with_all_values) # préprocessing : normalisation et traitement des valeurs manquantes\\n# pour normaliser -> fit_transform sur les données d\\'entrainement avec le scaler\\n# pour les valeurs manquantes -> fit sur les données d\\'entrainement avec l\\'imputer\\n# ### Evaluation du modèle\\nlog_reg_naive.score(test_without_nan[X_features], test_without_nan[\"Survived\"])\\n# \\nlog_reg.score(test_scaled_imputed, y_test_with_all_values) \\n# modèle pour la classification\\n\\nLogistic\\nRegression: sklearn.linear_model.LogisticRegression\\nDecision\\nTrees: sklearn.tree.DecisionTreeClassifier\\nRandom\\nForest: sklearn.ensemble.RandomForestClassifier\\nSupport\\nVector\\nMachines(SVM): sklearn.svm.SVC\\nk - Nearest\\nNeighbors(k - NN): sklearn.neighbors.KNeighborsClassifier\\nNaive\\nBayes: sklearn.naive_bayes.GaussianNB(\\nfor Gaussian Naive Bayes) or sklearn.naive_bayes.MultinomialNB ( for Multinomial Naive Bayes)\\nGradient\\nBoosting: sklearn.ensemble.GradientBoostingClassifier\\nAdaBoost: sklearn.ensemble.AdaBoostClassifier\\nNeural\\nNetworks: sklearn.neural_network.MLPClassifier\\nLinear\\nDiscriminant\\nAnalysis(LDA): sklearn.discriminant_analysis.LinearDiscriminantAnalysis\\nQuadratic\\nDiscriminant\\nAnalysis(QDA): sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis\\nStochastic\\nGradient\\nDescent(SGD): sklearn.linear_model.SGDClassifier\\nRidge\\nClassifier: sklearn.linear_model.RidgeClassifier\\nPerceptron: sklearn.linear_model.Perceptron\\n\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import GradientBoostingClassifier\\nfrom sklearn.ensemble import AdaBoostClassifier\\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\\nfrom sklearn.linear_model import SGDClassifier\\nfrom sklearn.linear_model import RidgeClassifier\\nfrom sklearn.linear_model import Perceptron\\nfrom sklearn.linear_model import LinearRegression\\n# Make a function that fit and score a list of models on a given dataset\\ndef fit_and_score(models, X_train, y_train, X_test, y_test):\\n\\nFit and score\\na\\nlist\\nof\\nmodels\\non\\na\\ngiven\\ndataset\\nArgs:\\nmodels(list): a\\nlist\\nof\\nmodels\\nX_train(DataFrame): the\\ntraining\\nset\\ny_train(Series): the\\ntraining\\nlabels\\nX_test(DataFrame): the\\ntest\\nset\\ny_test(Series): the\\ntest\\nlabels\\n\\nfor model in models:\\n    model.fit(X_train, y_train)\\n    print(f\"{model.__class__.__name__} score: {model.score(X_test, y_test)}\")\\nmodels = [\\nKNeighborsClassifier(n_neighbors=5),  # Adjust n_neighbors as needed\\nLogisticRegression(max_iter=1000),  # Adjust max_iter as needed\\nRandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),  # Adjust n_estimators and max_depth as needed\\nSVC(C=1, kernel=\\'rbf\\', gamma=\\'scale\\'),  # Adjust C, kernel, and gamma as needed\\nMLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),  # Adjust hidden_layer_sizes and max_iter as needed\\nDecisionTreeClassifier(max_depth=5, random_state=42),  # Adjust max_depth as needed\\nGradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),  # Adjust n_estimators, learning_rate, and max_depth as needed\\nAdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42),  # Adjust n_estimators and learning_rate as needed\\nLinearDiscriminantAnalysis(),\\nQuadraticDiscriminantAnalysis(),\\nSGDClassifier(max_iter=1000, random_state=42),  # Adjust max_iter as needed\\nRidgeClassifier(),\\nPerceptron(max_iter=1000, random_state=42),  # Adjust max_iter as needed\\nLinearRegression()\\n]\\nfit_and_score(models, train_scaled_imputed, y_with_all_values, test_scaled_imputed, y_test_with_all_values)\\n# Models pour la régression\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.linear_model import Lasso\\nfrom sklearn.linear_model import Ridge\\nfrom sklearn.tree import DecisionTreeRegressor\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.ensemble import GradientBoostingRegressor\\nfrom sklearn.svm import SVR\\nfrom sklearn.neighbors import KNeighborsRegressor\\nfrom sklearn.linear_model import ElasticNet\\nfrom sklearn.linear_model import HuberRegressor\\nfrom sklearn.linear_model import TheilSenRegressor\\n\\nmodels = [ #models de regression\\nLinearRegression(),\\nLasso(),\\nRidge(),\\nDecisionTreeRegressor(),\\nRandomForestRegressor(),\\nGradientBoostingRegressor(),\\nSVR(),\\nKNeighborsRegressor(),\\nElasticNet(),\\nHuberRegressor(),\\nTheilSenRegressor()\\n]\\n\\nfit_and_score(models, train_scaled_imputed, y_with_all_values, test_scaled_imputed, y_test_with_all_values)\\n'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "IUT Paul Sabatier\n",
    "Département Informatique\n",
    "BUT3 - R5.08 (AGED)\n",
    "2023-2024\n",
    "Contrôle 1\n",
    "Durée 2h20\n",
    "Le contrôle comporte deux parties : un QCM (20 minutes) + un Exercice\n",
    "Documents autorisés\n",
    "Exercice à réaliser de préférence sur un ordinateur. Le fichier produit doit être téléversé sur\n",
    "Moodle (dans le dossier Contrôle1).\n",
    "Exercice :\n",
    "On souhaite mettre en place un modèle de machine learning capable de prédire le statut\n",
    "tabagique (fumeur ou non fumeur) d'un patient à partir d'informations sur divers autres\n",
    "indicateurs de santé et autre.\n",
    "Les indicateurs sont listés dans le tableau ci-dessous.\n",
    "Le dataset est sur Moodle (train.new.csv.zip), il comporte une centaine de milliers de\n",
    "données vous pourrez l'exploiter comme vous le souhaitez.\n",
    "Question 1 :\n",
    "On vous demande de proposer d’indiquer le (vôtre) modèle d'apprentissage le plus optimal.\n",
    "Votre solution doit au moins tester trois algorithmes différents (trois modèles de machine\n",
    "learning).\n",
    "Il sera tenu compte dans l'évaluation de toute la procédure que vous avez choisie pour :\n",
    "- la préparation des données\n",
    "- le choix des variables importantes/utiles (avec des visualisations de données\n",
    "appropriées pour effectuer ces choix)\n",
    "- le choix des modèles d'apprentissage\n",
    "- la méthodologie d'évaluation\n",
    "- le rendu des résultats des évaluations (les performances) des différentes solutions.\n",
    "Le dataset comporte les données suivantes :\n",
    "age âge :\n",
    "sex sexe\n",
    "height(cm) taille(cm)\n",
    "country Pays\n",
    "weight(kg) poids(kg)\n",
    "waist(cm) : Waist circumference length taille(cm) : Tour de taille longueur\n",
    "eyesight(left) vue (gauche)\n",
    "eyesight(right) vue (droite)\n",
    "hearing(left) ouïe(gauche)\n",
    "hearing(right) ouïe(droite)\n",
    "systolic : Blood pressure systolique : Pression artérielle\n",
    "relaxation : Blood pressure relaxation : tension artérielle\n",
    "fasting blood sugar glycémie à jeun\n",
    "Cholesterol : total Cholestérol : total\n",
    "triglyceride triglycérides\n",
    "HDL : cholesterol type HDL : type de cholestérol\n",
    "LDL : cholesterol type LDL : type de cholestérol\n",
    "hemoglobin hémoglobine\n",
    "Urine protein Protéines urinaires\n",
    "serum creatinine créatinine sérique\n",
    "AST : glutamic oxaloacetic transaminase type AST : type de transaminase glutamique\n",
    "oxaloacétique\n",
    "ALT : glutamic oxaloacetic transaminase type ALT : transaminase glutamique oxaloacétique\n",
    "type\n",
    "Gtp : γ-GTP Gtp : γ-GTP\n",
    "dental caries caries dentaires\n",
    "smoking tabagisme\n",
    "Question 2 :\n",
    "Donner la valeur prédite par votre algorithme optimal pour le patient ayant les indicateurs\n",
    "suivants :\n",
    "Id, 1891\n",
    "age, 35\n",
    "sex, M\n",
    "country, usa\n",
    "height(cm), 185\n",
    "weight(kg), 80\n",
    "waist(cm), 84.0\n",
    "eyesight(left), 1.2\n",
    "eyesight(right), 0.9\n",
    "hearing(left), 1\n",
    "hearing(right), 1\n",
    "systolic 130\n",
    "relaxation, 70\n",
    "fasting blood sugar, 99\n",
    "Cholesterol, 211\n",
    "triglyceride, 210\n",
    "HDL, 41\n",
    "LDL, 127\n",
    "hemoglobin, 15.6\n",
    "Urine protein, 1\n",
    "serum creatinine, 1.3\n",
    "AST, 22\n",
    "ALT, 13\n",
    "Gtp, 21\n",
    "dental caries 0\n",
    "Valeurs en ligne pour copie/coller :\n",
    "191 190 55 F usa 175 80 87.1 0.9 0.8 1 1 137\n",
    "89 177 170 96 43 108 14.5 1 1.1 26 41 20 0\n",
    "Question 3 (4pts) :\n",
    "Le dataset a été modifié, plus précisément la colonne smoking (le statut tabagique) a été\n",
    "affiné pour mieux séparer les statuts tabagiques certains de ceux qui ne le sont pas. Ainsi\n",
    "au lieu d’avoir deux valeurs possibles (1 : fumeur, 0 : non fumeur), La colonne smoking\n",
    "(statut tabagique) a été étendu à 3 valeurs possibles, de 0 à 2 (0: non fumeur, 1 : plutôt\n",
    "fumeur, 2 : certainement fumeur).\n",
    "Le nouveau fichier est : train.new.multi.csv.zip. Seule la colonne smoking a été modifiée.\n",
    "Proposer une solution (modèle d’apprentissage) permettant de prédire ce nouveau statut\n",
    "tabagique en fonction des indicateurs de santé d’un patient.\n",
    "Quelle est la classe prédite pour le patient suivant (les valeurs ci-dessous sont listées dans le\n",
    "même ordre que la liste du tableau ci-dessus.).:\n",
    "481 60 M usa 160 65 78.0 0.8 0.7 1 1 118 62\n",
    "97 154 88 37 100 12.6 1 0.5 23 14 9 0\n",
    "\n",
    "Voici le code que j'ai pu écrire pour un autre travail : \n",
    "# # TP5.2 -  Exercice (Récap)\n",
    "# On reprend le fichier titanic. La démarche qu'il faut suivre pour la mise en place d'un projet de machine learning est la suivante : \n",
    "# - Analyse des données du Dataset\n",
    "#   - Analayse de la forme :\n",
    "#       - Vérifier la taille du Dataset X\n",
    "#       - Identifier les variables et les labels et leurs types\n",
    "#       - Visualiser quelques données\n",
    "#       - Analyser les données manquantes\n",
    "#       \n",
    "#  - Pré-traitement des données\n",
    "#     - Elimination des colonnes inutiles\n",
    "#     - Traiter es valeurs manquantes\n",
    "#     - Encoder les colonnes non numériques\n",
    "#     - Selection de variables utiles \n",
    "#     - Afficher (uniquement les courbes à deux dimensions, par exemple la colonne 4 `X[:, 3]`, en fonction de la colonne 3, `X[:, 2]`)\n",
    "#     - Création des Train set et Test set \n",
    "#     - Normaliser des données des différentes colonnes \n",
    "# \n",
    "# - Définition du modèle de machine learning adéquat à la tâche (données)\n",
    "# - Evaluation et calcul de performances (ATTENTION Il faut choisir la bonne métrique).\n",
    "# \n",
    "# \n",
    "# ## Questions \n",
    "# En s'appuyant sur la démarche décrite ci-dessus, comparer les modèles dans les cas suivants :\n",
    "# - donnéees normalisées versus non normalisées\n",
    "# - données manquantes traitées versus non traitées\n",
    "# sur les deux données normalisées et non normalisées et évaluation de leurs performances.\n",
    "# - comparer différents (2 alogos d'apprentissage). <br>\n",
    "# \n",
    "# PS :\n",
    "# *** ATTENTION n'oubiez pas de normaliser aussi les données de test. \n",
    "# La normalisation des données ne peut se faire que sur les données d'apprentissage. \n",
    "# <span style=\"color:red\"> Il ne faut jamais normaliser avant de spliter les données.\n",
    "# Les données de test ne sont pas connues, un algo. d'apprentissage ne doit jamais utliser une quelconque donnée qui vient des données de test sinon **BIAIS*</span>\n",
    "# \n",
    "# <span style=\"color:green\"> La normalisatin doit donc utiliser le même modèle (```transformer```) que celui utilisé dans la phase d'apprentissage ET SURTOUT la même échelle.</span> \n",
    "# \n",
    "# Rappel : pour les données d'entrainement on uilise la méthode ```fit_tranform()```et pour les données de test, ```transform()```\n",
    "# \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "# ### 1 Le dataset\n",
    "# - Lecture du Dataset et Analyse des données\n",
    "def load_titanic() -> pd.DataFrame:\n",
    "\n",
    "Load\n",
    "the\n",
    "titanic\n",
    "dataset.\n",
    "Returns:\n",
    "DataFrame: the\n",
    "titanic\n",
    "dataset.\n",
    "\n",
    "titanic = pd.read_csv('./data/titanic.csv')\n",
    "return titanic\n",
    "\n",
    "raw_titanic_data = load_titanic()\n",
    "# #### Coup d'oeil rapide sur le contenu .head()\n",
    "raw_titanic_data.head(3)\n",
    "# #### Vérification taille, type des données \n",
    "# \n",
    "raw_titanic_data.info()\n",
    "# #### Types variables\n",
    "# #### Analyse des données manquantes  \n",
    "# - Combien de valeurs manquantes (selon l'objet renvoyé, pandas ou numpy)\n",
    "# - On peut caculer le pourcentage de valeurs manquantes  *data.isnull().sum()/data.shape[0])* \n",
    "raw_titanic_data.isna().sum()/raw_titanic_data.shape[0]*100\n",
    "# #### Visualisation (Survived le label en fonction des variables)\n",
    "sns.pairplot(raw_titanic_data, hue='Survived')\n",
    "# #### Matrice de correlation \n",
    "sns.heatmap(raw_titanic_data.corr(), annot=True)\n",
    "# ### 2. Pré-traitement des données \n",
    "# #### Elimination colonnes inutiles\n",
    "# - Utiliser uniquement 'Survived', 'Pclass', 'Sex', 'Age', 'Fare'\n",
    "titanic = raw_titanic_data[['Survived', 'Pclass', 'Sex', 'Age', 'Fare']]\n",
    "X_features = [\"Pclass\", \"Sex\", \"Age\", \"Fare\"]\n",
    "titanic[\"Sex\"] = titanic['Sex'].replace(['male', 'female'], [0, 1])\n",
    "titanic.head(3)\n",
    "\n",
    "\n",
    "# #### Traiter les valeurs manquantes\n",
    "# - Deux cas : utiliser un imputer ou supprimer toutes les lignes vides\n",
    "#Avant quoique ce soit on sépare les données en train et test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(titanic, test_size=0.2, random_state=42)\n",
    "\n",
    "train_without_nan = train.dropna()\n",
    "test_without_nan = test.dropna() #dropna supprime les lignes qui ont des valeurs manquantes\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"mean\", missing_values=np.nan)\n",
    "imputer.fit(train[X_features]) # le imputer sert a remplacer les valeurs manquantes par la moyenne\n",
    "y_with_all_values = train[\"Survived\"]\n",
    "y_test_with_all_values = test[\"Survived\"]\n",
    "train_imputed = imputer.transform(train[X_features])\n",
    "test_imputed = imputer.transform(test[X_features])\n",
    "\n",
    "\n",
    "# #### Encodage des données non numériques ?\n",
    "#Pas besoin l'encodage des données non numériques car on a déjà fait le remplacement des valeurs sexes\n",
    "# mais pour encoder on utilise la méthode LabelEncoder\n",
    "# #### Normalisation \n",
    "# Attention la normalisation à la normalisation des données de test.\n",
    "#Normalisation des données\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_imputed)\n",
    "train_scaled_imputed = scaler.transform(train_imputed)\n",
    "test_scaled_imputed = scaler.transform(test_imputed)\n",
    "\n",
    "train_scaled_imputed\n",
    "# ### Pré-processing des données\n",
    "\n",
    "\n",
    "# #### Visualisation de de queques données (normalisées et non non normalisées) ?\n",
    "plt.scatter(range(0, len(train_scaled_imputed[:,2])), train_scaled_imputed[:,2])\n",
    "plt.scatter(range(0,len(train[\"Age\"])), train[\"Age\"])\n",
    "plt.title(\"Age\")\n",
    "\n",
    "plt.scatter(range(0, len(train_scaled_imputed[:,3])), train_scaled_imputed[:,3])\n",
    "plt.scatter(range(0,len(train[\"Fare\"])), train[\"Fare\"])\n",
    "plt.scatter(range(0, len(train_scaled_imputed[:,0])), train_scaled_imputed[:,0])\n",
    "plt.scatter(range(0,len(train[\"Pclass\"])), train[\"Pclass\"])\n",
    "plt.title(\"Pclass\")\n",
    "plt.scatter(range(0, len(train_scaled_imputed[:,1])), train_scaled_imputed[:,1])\n",
    "plt.scatter(range(0,len(train[\"Sex\"])), train[\"Sex\"])\n",
    "\n",
    "# ## Modélisation\n",
    "#Modelisation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n=5\n",
    "log_reg = KNeighborsClassifier(n_neighbors=n)\n",
    "log_reg_naive = KNeighborsClassifier(n_neighbors=n)\n",
    "# ### Entrainement\n",
    "log_reg_naive.fit(train_without_nan[X_features],train_without_nan[\"Survived\"]) # no préprocessing (pas de normalisation, pas de traitement des valeurs manquantes)\n",
    "log_reg.fit(train_scaled_imputed, y_with_all_values) # préprocessing : normalisation et traitement des valeurs manquantes\n",
    "# pour normaliser -> fit_transform sur les données d'entrainement avec le scaler\n",
    "# pour les valeurs manquantes -> fit sur les données d'entrainement avec l'imputer\n",
    "# ### Evaluation du modèle\n",
    "log_reg_naive.score(test_without_nan[X_features], test_without_nan[\"Survived\"])\n",
    "# \n",
    "log_reg.score(test_scaled_imputed, y_test_with_all_values) \n",
    "# modèle pour la classification\n",
    "\n",
    "Logistic\n",
    "Regression: sklearn.linear_model.LogisticRegression\n",
    "Decision\n",
    "Trees: sklearn.tree.DecisionTreeClassifier\n",
    "Random\n",
    "Forest: sklearn.ensemble.RandomForestClassifier\n",
    "Support\n",
    "Vector\n",
    "Machines(SVM): sklearn.svm.SVC\n",
    "k - Nearest\n",
    "Neighbors(k - NN): sklearn.neighbors.KNeighborsClassifier\n",
    "Naive\n",
    "Bayes: sklearn.naive_bayes.GaussianNB(\n",
    "for Gaussian Naive Bayes) or sklearn.naive_bayes.MultinomialNB ( for Multinomial Naive Bayes)\n",
    "Gradient\n",
    "Boosting: sklearn.ensemble.GradientBoostingClassifier\n",
    "AdaBoost: sklearn.ensemble.AdaBoostClassifier\n",
    "Neural\n",
    "Networks: sklearn.neural_network.MLPClassifier\n",
    "Linear\n",
    "Discriminant\n",
    "Analysis(LDA): sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
    "Quadratic\n",
    "Discriminant\n",
    "Analysis(QDA): sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis\n",
    "Stochastic\n",
    "Gradient\n",
    "Descent(SGD): sklearn.linear_model.SGDClassifier\n",
    "Ridge\n",
    "Classifier: sklearn.linear_model.RidgeClassifier\n",
    "Perceptron: sklearn.linear_model.Perceptron\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Make a function that fit and score a list of models on a given dataset\n",
    "def fit_and_score(models, X_train, y_train, X_test, y_test):\n",
    "\n",
    "Fit and score\n",
    "a\n",
    "list\n",
    "of\n",
    "models\n",
    "on\n",
    "a\n",
    "given\n",
    "dataset\n",
    "Args:\n",
    "models(list): a\n",
    "list\n",
    "of\n",
    "models\n",
    "X_train(DataFrame): the\n",
    "training\n",
    "set\n",
    "y_train(Series): the\n",
    "training\n",
    "labels\n",
    "X_test(DataFrame): the\n",
    "test\n",
    "set\n",
    "y_test(Series): the\n",
    "test\n",
    "labels\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{model.__class__.__name__} score: {model.score(X_test, y_test)}\")\n",
    "models = [\n",
    "KNeighborsClassifier(n_neighbors=5),  # Adjust n_neighbors as needed\n",
    "LogisticRegression(max_iter=1000),  # Adjust max_iter as needed\n",
    "RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),  # Adjust n_estimators and max_depth as needed\n",
    "SVC(C=1, kernel='rbf', gamma='scale'),  # Adjust C, kernel, and gamma as needed\n",
    "MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),  # Adjust hidden_layer_sizes and max_iter as needed\n",
    "DecisionTreeClassifier(max_depth=5, random_state=42),  # Adjust max_depth as needed\n",
    "GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),  # Adjust n_estimators, learning_rate, and max_depth as needed\n",
    "AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42),  # Adjust n_estimators and learning_rate as needed\n",
    "LinearDiscriminantAnalysis(),\n",
    "QuadraticDiscriminantAnalysis(),\n",
    "SGDClassifier(max_iter=1000, random_state=42),  # Adjust max_iter as needed\n",
    "RidgeClassifier(),\n",
    "Perceptron(max_iter=1000, random_state=42),  # Adjust max_iter as needed\n",
    "LinearRegression()\n",
    "]\n",
    "fit_and_score(models, train_scaled_imputed, y_with_all_values, test_scaled_imputed, y_test_with_all_values)\n",
    "# Models pour la régression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "\n",
    "models = [ #models de regression\n",
    "LinearRegression(),\n",
    "Lasso(),\n",
    "Ridge(),\n",
    "DecisionTreeRegressor(),\n",
    "RandomForestRegressor(),\n",
    "GradientBoostingRegressor(),\n",
    "SVR(),\n",
    "KNeighborsRegressor(),\n",
    "ElasticNet(),\n",
    "HuberRegressor(),\n",
    "TheilSenRegressor()\n",
    "]\n",
    "\n",
    "fit_and_score(models, train_scaled_imputed, y_with_all_values, test_scaled_imputed, y_test_with_all_values)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:21.608909400Z",
     "start_time": "2023-11-23T09:50:21.255025Z"
    }
   },
   "id": "9bb7bfb8198ba460"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159255\n"
     ]
    },
    {
     "data": {
      "text/plain": "   id  age  sex country  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n0   0   55    M     usa         165          60       81.0             0.5   \n1   1   70  NaN     usa         165          65       89.0             0.6   \n2   2   20    M     usa         170          75       81.0             0.4   \n3   3   35    F     usa         180          95      105.0             1.5   \n4   4   30    M     usa         165          60       80.5             1.5   \n\n   eyesight(right)  hearing(left)  ...  HDL  LDL  hemoglobin  Urine protein  \\\n0              0.6              1  ...   40   75        16.5              1   \n1              0.7              2  ...   57  126        16.2              1   \n2              0.5              1  ...   45   93        17.4              1   \n3              1.2              1  ...   38  102        15.9              1   \n4              1.0              1  ...   44   93        15.4              1   \n\n   serum creatinine  AST  ALT  Gtp  dental caries  smoking  \n0               1.0   22   25   27              0        1  \n1               1.1   27   23   37              1        0  \n2               0.8   27   31   53              0        1  \n3               1.0   20   27   30              1        0  \n4               0.8   19   13   17              0        1  \n\n[5 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>country</th>\n      <th>height(cm)</th>\n      <th>weight(kg)</th>\n      <th>waist(cm)</th>\n      <th>eyesight(left)</th>\n      <th>eyesight(right)</th>\n      <th>hearing(left)</th>\n      <th>...</th>\n      <th>HDL</th>\n      <th>LDL</th>\n      <th>hemoglobin</th>\n      <th>Urine protein</th>\n      <th>serum creatinine</th>\n      <th>AST</th>\n      <th>ALT</th>\n      <th>Gtp</th>\n      <th>dental caries</th>\n      <th>smoking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>55</td>\n      <td>M</td>\n      <td>usa</td>\n      <td>165</td>\n      <td>60</td>\n      <td>81.0</td>\n      <td>0.5</td>\n      <td>0.6</td>\n      <td>1</td>\n      <td>...</td>\n      <td>40</td>\n      <td>75</td>\n      <td>16.5</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>22</td>\n      <td>25</td>\n      <td>27</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>70</td>\n      <td>NaN</td>\n      <td>usa</td>\n      <td>165</td>\n      <td>65</td>\n      <td>89.0</td>\n      <td>0.6</td>\n      <td>0.7</td>\n      <td>2</td>\n      <td>...</td>\n      <td>57</td>\n      <td>126</td>\n      <td>16.2</td>\n      <td>1</td>\n      <td>1.1</td>\n      <td>27</td>\n      <td>23</td>\n      <td>37</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>20</td>\n      <td>M</td>\n      <td>usa</td>\n      <td>170</td>\n      <td>75</td>\n      <td>81.0</td>\n      <td>0.4</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>...</td>\n      <td>45</td>\n      <td>93</td>\n      <td>17.4</td>\n      <td>1</td>\n      <td>0.8</td>\n      <td>27</td>\n      <td>31</td>\n      <td>53</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>35</td>\n      <td>F</td>\n      <td>usa</td>\n      <td>180</td>\n      <td>95</td>\n      <td>105.0</td>\n      <td>1.5</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>38</td>\n      <td>102</td>\n      <td>15.9</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>20</td>\n      <td>27</td>\n      <td>30</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>30</td>\n      <td>M</td>\n      <td>usa</td>\n      <td>165</td>\n      <td>60</td>\n      <td>80.5</td>\n      <td>1.5</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>44</td>\n      <td>93</td>\n      <td>15.4</td>\n      <td>1</td>\n      <td>0.8</td>\n      <td>19</td>\n      <td>13</td>\n      <td>17</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train.new.csv')\n",
    "#print nombre de lignes : \n",
    "print(train.shape[0])\n",
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:21.638229900Z",
     "start_time": "2023-11-23T09:50:21.268228300Z"
    }
   },
   "id": "ff48e70be52804ec"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "\"<class 'pandas.core.frame.DataFrame'>\\nRangeIndex: 159255 entries, 0 to 159254\\nData columns (total 26 columns):\\n #   Column               Non-Null Count   Dtype  \\n---  ------               --------------   -----  \\n 0   id                   159255 non-null  int64  \\n 1   age                  159255 non-null  int64  \\n 2   sex                  136625 non-null  object \\n 3   country              159255 non-null  object \\n 4   height(cm)           159255 non-null  int64  \\n 5   weight(kg)           159255 non-null  int64  \\n 6   waist(cm)            159255 non-null  float64\\n 7   eyesight(left)       159255 non-null  float64\\n 8   eyesight(right)      159255 non-null  float64\\n 9   hearing(left)        159255 non-null  int64  \\n 10  hearing(right)       159255 non-null  int64  \\n 11  systolic             159255 non-null  int64  \\n 12  relaxation           159255 non-null  int64  \\n 13  fasting blood sugar  159255 non-null  int64  \\n 14  Cholesterol          159255 non-null  int64  \\n 15  triglyceride         159255 non-null  int64  \\n 16  HDL                  159255 non-null  int64  \\n 17  LDL                  159255 non-null  int64  \\n 18  hemoglobin           159255 non-null  float64\\n 19  Urine protein        159255 non-null  int64  \\n 20  serum creatinine     159255 non-null  float64\\n 21  AST                  159255 non-null  int64  \\n 22  ALT                  159255 non-null  int64  \\n 23  Gtp                  159255 non-null  int64  \\n 24  dental caries        159255 non-null  int64  \\n 25  smoking              159255 non-null  int64  \\ndtypes: float64(5), int64(19), object(2)\\nmemory usage: 31.6+ MB\\n\""
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "#train.info()\n",
    "\n",
    "\"\"\"<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 159255 entries, 0 to 159254\n",
    "Data columns (total 26 columns):\n",
    " #   Column               Non-Null Count   Dtype  \n",
    "---  ------               --------------   -----  \n",
    " 0   id                   159255 non-null  int64  \n",
    " 1   age                  159255 non-null  int64  \n",
    " 2   sex                  136625 non-null  object \n",
    " 3   country              159255 non-null  object \n",
    " 4   height(cm)           159255 non-null  int64  \n",
    " 5   weight(kg)           159255 non-null  int64  \n",
    " 6   waist(cm)            159255 non-null  float64\n",
    " 7   eyesight(left)       159255 non-null  float64\n",
    " 8   eyesight(right)      159255 non-null  float64\n",
    " 9   hearing(left)        159255 non-null  int64  \n",
    " 10  hearing(right)       159255 non-null  int64  \n",
    " 11  systolic             159255 non-null  int64  \n",
    " 12  relaxation           159255 non-null  int64  \n",
    " 13  fasting blood sugar  159255 non-null  int64  \n",
    " 14  Cholesterol          159255 non-null  int64  \n",
    " 15  triglyceride         159255 non-null  int64  \n",
    " 16  HDL                  159255 non-null  int64  \n",
    " 17  LDL                  159255 non-null  int64  \n",
    " 18  hemoglobin           159255 non-null  float64\n",
    " 19  Urine protein        159255 non-null  int64  \n",
    " 20  serum creatinine     159255 non-null  float64\n",
    " 21  AST                  159255 non-null  int64  \n",
    " 22  ALT                  159255 non-null  int64  \n",
    " 23  Gtp                  159255 non-null  int64  \n",
    " 24  dental caries        159255 non-null  int64  \n",
    " 25  smoking              159255 non-null  int64  \n",
    "dtypes: float64(5), int64(19), object(2)\n",
    "memory usage: 31.6+ MB\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:21.639607300Z",
     "start_time": "2023-11-23T09:50:21.531980200Z"
    }
   },
   "id": "eb4b4a68ce94762"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# préprocessing des données\n",
    "# On supprime les colonnes inutiles\n",
    "#on constate que toutes les données sont numériques sauf le sexe et le pays\n",
    "# affichage tout pays distincts\n",
    "#distinctcountry = train['country'].unique()\n",
    "#print(distinctcountry) (il n y a qu'un seul pays donc on peux virer la donnée vu qu'elle ne varie pas.)\n",
    "train = train.drop(['id', 'country'], axis=1)\n",
    "#train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:21.639607300Z",
     "start_time": "2023-11-23T09:50:21.549598700Z"
    }
   },
   "id": "679f8fb3165738fd"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "age                    0\nsex                    0\nheight(cm)             0\nweight(kg)             0\nwaist(cm)              0\neyesight(left)         0\neyesight(right)        0\nhearing(left)          0\nhearing(right)         0\nsystolic               0\nrelaxation             0\nfasting blood sugar    0\nCholesterol            0\ntriglyceride           0\nHDL                    0\nLDL                    0\nhemoglobin             0\nUrine protein          0\nserum creatinine       0\nAST                    0\nALT                    0\nGtp                    0\ndental caries          0\nsmoking                0\ndtype: int64"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on regarde si il manque des valeurs\n",
    "train.isna().sum() #essentiellement des valeurs manquantes pour le sexe\n",
    "# supression des lignes avec des valeurs manquantes\n",
    "train = train.dropna()\n",
    "train.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:21.774839700Z",
     "start_time": "2023-11-23T09:50:21.579644500Z"
    }
   },
   "id": "fdf2c196945afe1d"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# pas besoin d'encoder les données non numériques car elles sont toutes numériques"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:21.775840400Z",
     "start_time": "2023-11-23T09:50:21.657618700Z"
    }
   },
   "id": "a1cd72f16921c766"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5330      0\n",
      "3173      1\n",
      "155396    1\n",
      "51113     1\n",
      "87838     0\n",
      "         ..\n",
      "64302     0\n",
      "32443     0\n",
      "45643     0\n",
      "95101     1\n",
      "82865     1\n",
      "Name: sex, Length: 27325, dtype: int32\n",
      "19006     1\n",
      "135531    0\n",
      "65106     1\n",
      "46672     0\n",
      "124608    1\n",
      "         ..\n",
      "128490    1\n",
      "139738    0\n",
      "120869    1\n",
      "153785    0\n",
      "142180    1\n",
      "Name: sex, Length: 109300, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# on sépare les données en train et test \n",
    "# est-ce que la personne fume ou pas\n",
    "X = train.drop(['smoking'], axis=1)\n",
    "y = train['smoking']\n",
    "# on sépare les données en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X_train['sex'] = le.fit_transform(X_train['sex'])\n",
    "X_test['sex'] = le.fit_transform(X_test['sex'])\n",
    "print(X_test['sex'])\n",
    "print(X_train['sex'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:21.860174500Z",
     "start_time": "2023-11-23T09:50:21.686623600Z"
    }
   },
   "id": "5e8b0c251e9e76d6"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# on normalise les données pour accélérer le processus d'apprentissage\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:21.947398800Z",
     "start_time": "2023-11-23T09:50:21.783240700Z"
    }
   },
   "id": "30ca4643cc941319"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# on va tester plusieurs modèles pour voir lequel est le plus performant"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:21.950399900Z",
     "start_time": "2023-11-23T09:50:21.858888300Z"
    }
   },
   "id": "4b0fca8a3df20eff"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b96aee6d58f17792"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression score: 0.7474473924977127\n",
      "KNeighborsClassifier score: 0.7234034766697164\n",
      "RandomForestClassifier score: 0.7717840805123514\n"
     ]
    }
   ],
   "source": [
    "models = [ # models de classification car on cherche à savoir si la personne fume ou pas\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    "    #DecisionTreeClassifier(),\n",
    "    RandomForestClassifier()\n",
    "    #AdaBoostClassifier(),\n",
    "    #MLPClassifier(max_iter=1000),\n",
    "    #SVC(),\n",
    "    #GaussianNB()\n",
    "]\n",
    "def fit_and_score(models, X_train, y_train, X_test, y_test):\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        print(f\"{model.__class__.__name__} score: {model.score(X_test, y_test)}\")\n",
    "        \n",
    "fit_and_score(models, X_train_scaled, y_train, X_test_scaled, y_test) # le code met beaucoup de temps à s'exécuter"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:47.125321500Z",
     "start_time": "2023-11-23T09:50:21.887434900Z"
    }
   },
   "id": "6340a03f282ce63c"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "'LogisticRegression score: 0.7474473924977127\\nKNeighborsClassifier score: 0.7234034766697164\\nDecisionTreeClassifier score: 0.6905032021957914\\nRandomForestClassifier score: 0.7701372369624886\\nAdaBoostClassifier score: 0.7640256175663312\\nMLPClassifier score: 0.7656724611161939'"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"LogisticRegression score: 0.7474473924977127\n",
    "KNeighborsClassifier score: 0.7234034766697164\n",
    "DecisionTreeClassifier score: 0.6905032021957914\n",
    "RandomForestClassifier score: 0.7701372369624886\n",
    "AdaBoostClassifier score: 0.7640256175663312\n",
    "MLPClassifier score: 0.7656724611161939\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:47.185285700Z",
     "start_time": "2023-11-23T09:50:47.126508Z"
    }
   },
   "id": "25349ce4942dde41"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# on va essayer de trouver les meilleurs paramètres pour le modèle de random forest\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:47.197235600Z",
     "start_time": "2023-11-23T09:50:47.142497100Z"
    }
   },
   "id": "abd8b907e3c8683"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7404574565416285"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimator = 10\n",
    "rfc = RandomForestClassifier(n_estimator)\n",
    "rfc.fit(X_train_scaled, y_train)\n",
    "rfc.score(X_test_scaled, y_test) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:49.273040500Z",
     "start_time": "2023-11-23T09:50:47.161778100Z"
    }
   },
   "id": "7d20a3a89e2fdec2"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7404574565416285\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_test_scaled)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:49.344876400Z",
     "start_time": "2023-11-23T09:50:49.268566300Z"
    }
   },
   "id": "bfd02eff4dc59bac"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score sur X_train:  0.9900365965233303\n",
      "Accuracy sur le train : 0.9900365965233303\n",
      "Precision sur le train : 0.9928998820158436\n",
      "F1  sur le train : 0.9885780812435104\n",
      "Recall sur le train : 0.9842937404707701\n"
     ]
    },
    {
     "data": {
      "text/plain": "'score sur X_train:  0.989341262580055\\nAccuracy sur le train : 0.989341262580055\\nPrecision sur le train : 0.9936802502536355\\nF1  sur le train : 0.9877614480360538\\nRecall sur le train : 0.9819127383612858'"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "# test avec Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_random_forest = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "# Train\n",
    "model_random_forest.fit(X_train, y_train)\n",
    "\n",
    "# predict sur X_train\n",
    "y_pred_random_forest = model_random_forest.predict(X_train)\n",
    "\n",
    "# on calcule le score\n",
    "score_random_forest = model_random_forest.score(X_train, y_train)\n",
    "\n",
    "print(\"score sur X_train: \", score_random_forest)\n",
    "print('Accuracy sur le train :', accuracy_score(y_train, y_pred_random_forest))\n",
    "print('Precision sur le train :', precision_score(y_train, y_pred_random_forest))\n",
    "print('F1  sur le train :', f1_score(y_train, y_pred_random_forest))\n",
    "print('Recall sur le train :', recall_score(y_train, y_pred_random_forest))\n",
    "\n",
    "\"\"\"score sur X_train:  0.989341262580055\n",
    "Accuracy sur le train : 0.989341262580055\n",
    "Precision sur le train : 0.9936802502536355\n",
    "F1  sur le train : 0.9877614480360538\n",
    "Recall sur le train : 0.9819127383612858\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:51.967113600Z",
     "start_time": "2023-11-23T09:50:49.348372Z"
    }
   },
   "id": "dfbce834de1bef84"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score sur X_test:  0.744007319304666\n",
      "Accuracy sur le test : 0.744007319304666\n",
      "Precision sur le test : 0.7132650426099681\n",
      "F1  sur le test : 0.7031866593117495\n",
      "Recall sur le test : 0.6933891213389122\n"
     ]
    },
    {
     "data": {
      "text/plain": "'score sur X_test:  0.7414455626715462\\nAccuracy sur le test : 0.7414455626715462\\nPrecision sur le test : 0.7130025289962502\\nF1  sur le test : 0.6982961096639194\\nRecall sur le test : 0.68418410041841'"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict sur X_test\n",
    "y_pred_random_forest = model_random_forest.predict(X_test)\n",
    "\n",
    "# on calcule le score\n",
    "score_random_forest = model_random_forest.score(X_test, y_test)\n",
    "\n",
    "print(\"score sur X_test: \", score_random_forest)\n",
    "print('Accuracy sur le test :', accuracy_score(y_test, y_pred_random_forest))\n",
    "print('Precision sur le test :', precision_score(y_test, y_pred_random_forest))\n",
    "print('F1  sur le test :', f1_score(y_test, y_pred_random_forest))\n",
    "print('Recall sur le test :', recall_score(y_test, y_pred_random_forest))\n",
    "\"\"\"score sur X_test:  0.7414455626715462\n",
    "Accuracy sur le test : 0.7414455626715462\n",
    "Precision sur le test : 0.7130025289962502\n",
    "F1  sur le test : 0.6982961096639194\n",
    "Recall sur le test : 0.68418410041841\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:52.123482Z",
     "start_time": "2023-11-23T09:50:51.968633500Z"
    }
   },
   "id": "9aefeb5f3e380c90"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matrice de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred_random_forest)\n",
    "# On calcule la matrice de confusion (on utilise le result de random forest qui est le plus performant)\n",
    "cm = confusion_matrix(y_test, y_pred_random_forest)\n",
    "# affichage\n",
    "sns.heatmap(cm, annot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:52.255848100Z",
     "start_time": "2023-11-23T09:50:52.124488500Z"
    }
   },
   "id": "20c68a3fbdda93e"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "' \\nId, 1891\\nage, 35\\nsex, M\\ncountry, usa\\nheight(cm), 185\\nweight(kg), 80\\nwaist(cm), 84.0\\neyesight(left), 1.2\\neyesight(right), 0.9\\nhearing(left), 1\\nhearing(right), 1\\nsystolic 130\\nrelaxation, 70\\nfasting blood sugar, 99\\nCholesterol, 211\\ntriglyceride, 210\\nHDL, 41\\nLDL, 127\\nhamoglobin, 15.6\\nUrine protein, 1\\nserum creatinine, 1.3\\nAST, 22\\nALT, 13\\nGtp, 21\\ndental caries 0\\n'"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Partie 2 :\n",
    "# Donner la valeur prédite par votre algorithme optimal pour le patient ayant les indicateurs suivants :\n",
    "\"\"\" \n",
    "Id, 1891\n",
    "age, 35\n",
    "sex, M\n",
    "country, usa\n",
    "height(cm), 185\n",
    "weight(kg), 80\n",
    "waist(cm), 84.0\n",
    "eyesight(left), 1.2\n",
    "eyesight(right), 0.9\n",
    "hearing(left), 1\n",
    "hearing(right), 1\n",
    "systolic 130\n",
    "relaxation, 70\n",
    "fasting blood sugar, 99\n",
    "Cholesterol, 211\n",
    "triglyceride, 210\n",
    "HDL, 41\n",
    "LDL, 127\n",
    "hamoglobin, 15.6\n",
    "Urine protein, 1\n",
    "serum creatinine, 1.3\n",
    "AST, 22\n",
    "ALT, 13\n",
    "Gtp, 21\n",
    "dental caries 0\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:52.265979900Z",
     "start_time": "2023-11-23T09:50:52.251842100Z"
    }
   },
   "id": "18d7651d6b34ad00"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Id  age sex country  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n",
      "0  1891   35   M     usa         185          80       84.0             1.2   \n",
      "\n",
      "   eyesight(right)  hearing(left)  ...  triglyceride  HDL  LDL  hemoglobin  \\\n",
      "0              0.9              1  ...           210   41  127        15.6   \n",
      "\n",
      "   Urine protein  serum creatinine  AST  ALT  Gtp  dental caries  \n",
      "0              1               1.3   22   13   21              0  \n",
      "\n",
      "[1 rows x 25 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Valeurs en ligne pour copie/coller :\\n191 190 55 F usa 175 80 87.1 0.9 0.8 1 1 137\\n89 177 170 96 43 108 14.5 1 1.1 26 41 20 0'"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient = pd.DataFrame({\n",
    "    'Id': [1891],\n",
    "    'age': [35],\n",
    "    'sex': ['M'],\n",
    "    'country': ['usa'],\n",
    "    'height(cm)': [185],\n",
    "    'weight(kg)': [80],\n",
    "    'waist(cm)': [84.0],\n",
    "    'eyesight(left)': [1.2],\n",
    "    'eyesight(right)': [0.9],\n",
    "    'hearing(left)': [1],\n",
    "    'hearing(right)': [1],\n",
    "    'systolic': [130],\n",
    "    'relaxation': [70],\n",
    "    'fasting blood sugar': [99],\n",
    "    'Cholesterol': [211],\n",
    "    'triglyceride': [210],\n",
    "    'HDL': [41],\n",
    "    'LDL': [127],\n",
    "    'hemoglobin': [15.6],\n",
    "    'Urine protein': [1],\n",
    "    'serum creatinine': [1.3],\n",
    "    'AST': [22],\n",
    "    'ALT': [13],\n",
    "    'Gtp': [21],\n",
    "    'dental caries': [0]\n",
    "})\n",
    "print(patient)\n",
    "\"\"\"Valeurs en ligne pour copie/coller :\n",
    "191 190 55 F usa 175 80 87.1 0.9 0.8 1 1 137\n",
    "89 177 170 96 43 108 14.5 1 1.1 26 41 20 0\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:52.341069100Z",
     "start_time": "2023-11-23T09:50:52.268492700Z"
    }
   },
   "id": "21cdc21a27002f19"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "   age  sex  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n0   35    1         185          80       84.0             1.2   \n\n   eyesight(right)  hearing(left)  hearing(right)  systolic  ...  \\\n0              0.9              1               1       130  ...   \n\n   triglyceride  HDL  LDL  hemoglobin  Urine protein  serum creatinine  AST  \\\n0           210   41  127        15.6              1               1.3   22   \n\n   ALT  Gtp  dental caries  \n0   13   21              0  \n\n[1 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>height(cm)</th>\n      <th>weight(kg)</th>\n      <th>waist(cm)</th>\n      <th>eyesight(left)</th>\n      <th>eyesight(right)</th>\n      <th>hearing(left)</th>\n      <th>hearing(right)</th>\n      <th>systolic</th>\n      <th>...</th>\n      <th>triglyceride</th>\n      <th>HDL</th>\n      <th>LDL</th>\n      <th>hemoglobin</th>\n      <th>Urine protein</th>\n      <th>serum creatinine</th>\n      <th>AST</th>\n      <th>ALT</th>\n      <th>Gtp</th>\n      <th>dental caries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35</td>\n      <td>1</td>\n      <td>185</td>\n      <td>80</td>\n      <td>84.0</td>\n      <td>1.2</td>\n      <td>0.9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>130</td>\n      <td>...</td>\n      <td>210</td>\n      <td>41</td>\n      <td>127</td>\n      <td>15.6</td>\n      <td>1</td>\n      <td>1.3</td>\n      <td>22</td>\n      <td>13</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on supprime les colonnes inutiles enlevez les # pour executer\n",
    "patient = patient.drop(['Id', 'country'], axis=1)\n",
    "# on transforme le sex en 0,1 avec label encoder\n",
    "patient['sex'] = le.transform(patient['sex'])\n",
    "patient.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:52.355319300Z",
     "start_time": "2023-11-23T09:50:52.282315700Z"
    }
   },
   "id": "163deefa192b27ad"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statut tabagique prédit: non fumeur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baran\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# prédire si le patient fume ou pas\n",
    "patient_df_scaled = scaler.transform(patient)\n",
    "prediction = model_random_forest.predict(patient_df_scaled)\n",
    "statut_tabagique = ['non fumeur', 'fumeur']\n",
    "patient_df_scaled = scaler.transform(patient)\n",
    "print(\"Statut tabagique prédit:\", statut_tabagique[prediction[0]])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:52.356316900Z",
     "start_time": "2023-11-23T09:50:52.297563800Z"
    }
   },
   "id": "3ecc74ae9d9bd51b"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "'Question 3 (4pts) :\\nLe dataset a été modifié, plus précisément la colonne smoking (le statut tabagique) a été\\naffiné pour mieux séparer les statuts tabagiques certains de ceux qui ne le sont pas. Ainsi\\nau lieu d’avoir deux valeurs possibles (1 : fumeur, 0 : non fumeur), La colonne smoking\\n(statut tabagique) a été étendu à 3 valeurs possibles, de 0 à 2 (0: non fumeur, 1 : plutôt\\nfumeur, 2 : certainement fumeur).\\nLe nouveau fichier est : train.new.multi.csv.zip. Seule la colonne smoking a été modifiée.\\nProposer une solution (modèle d’apprentissage) permettant de prédire ce nouveau statut\\ntabagique en fonction des indicateurs de santé d’un patient.\\nQuelle est la classe prédite pour le patient suivant (les valeurs ci-dessous sont listées dans le\\nmême ordre que la liste du tableau ci-dessus.).:\\n481 60 M usa 160 65 78.0 0.8 0.7 1 1 118 62\\n97 154 88 37 100 12.6 1 0.5 23 14 9 0'"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Question 3 (4pts) :\n",
    "Le dataset a été modifié, plus précisément la colonne smoking (le statut tabagique) a été\n",
    "affiné pour mieux séparer les statuts tabagiques certains de ceux qui ne le sont pas. Ainsi\n",
    "au lieu d’avoir deux valeurs possibles (1 : fumeur, 0 : non fumeur), La colonne smoking\n",
    "(statut tabagique) a été étendu à 3 valeurs possibles, de 0 à 2 (0: non fumeur, 1 : plutôt\n",
    "fumeur, 2 : certainement fumeur).\n",
    "Le nouveau fichier est : train.new.multi.csv.zip. Seule la colonne smoking a été modifiée.\n",
    "Proposer une solution (modèle d’apprentissage) permettant de prédire ce nouveau statut\n",
    "tabagique en fonction des indicateurs de santé d’un patient.\n",
    "Quelle est la classe prédite pour le patient suivant (les valeurs ci-dessous sont listées dans le\n",
    "même ordre que la liste du tableau ci-dessus.).:\n",
    "481 60 M usa 160 65 78.0 0.8 0.7 1 1 118 62\n",
    "97 154 88 37 100 12.6 1 0.5 23 14 9 0\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:52.357318100Z",
     "start_time": "2023-11-23T09:50:52.313957200Z"
    }
   },
   "id": "469d840c46fdfe52"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5257822506861848\n",
      "Precision: 0.4763983856150024\n",
      "Recall: 0.5257822506861848\n",
      "F1 Score: 0.48644772337572567\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'M'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_18260\\4046430136.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[0mpatient_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpatient_df\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 62\u001B[1;33m \u001B[0mpatient_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'sex'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mle_sex\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpatient_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'sex'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     63\u001B[0m \u001B[0mpatient_scaled\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mscaler_multi\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpatient_df\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[0mpatient_prediction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpatient_scaled\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\u001B[0m in \u001B[0;36mwrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    140\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mwraps\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    141\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 142\u001B[1;33m         \u001B[0mdata_to_wrap\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    143\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_to_wrap\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    144\u001B[0m             \u001B[1;31m# only wrap the first output for cross decomposition\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001B[0m in \u001B[0;36mtransform\u001B[1;34m(self, y)\u001B[0m\n\u001B[0;32m    132\u001B[0m         \"\"\"\n\u001B[0;32m    133\u001B[0m         \u001B[0mcheck_is_fitted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 134\u001B[1;33m         \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcolumn_or_1d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclasses_\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwarn\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    135\u001B[0m         \u001B[1;31m# transform of empty array is empty array\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    136\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0m_num_samples\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcolumn_or_1d\u001B[1;34m(y, dtype, warn)\u001B[0m\n\u001B[0;32m   1177\u001B[0m     \"\"\"\n\u001B[0;32m   1178\u001B[0m     \u001B[0mxp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_namespace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1179\u001B[1;33m     y = check_array(\n\u001B[0m\u001B[0;32m   1180\u001B[0m         \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1181\u001B[0m         \u001B[0mensure_2d\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    875\u001B[0m                             \u001B[0minput_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minput_name\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    876\u001B[0m                         )\n\u001B[1;32m--> 877\u001B[1;33m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    878\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    879\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_asarray_with_order\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mxp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py\u001B[0m in \u001B[0;36mastype\u001B[1;34m(self, x, dtype, copy, casting)\u001B[0m\n\u001B[0;32m     66\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcasting\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"unsafe\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m         \u001B[1;31m# astype is not defined in the top level NumPy namespace\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 68\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcasting\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcasting\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     69\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     70\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: invalid literal for int() with base 10: 'M'"
     ]
    }
   ],
   "source": [
    "# Chargement du dataset\n",
    "train_multi = pd.read_csv('./train.new.multi.csv')\n",
    "\n",
    "# Pré-traitement\n",
    "train_multi = train_multi.drop(['id', 'country'], axis=1)\n",
    "train_multi.dropna(inplace=True)\n",
    "train_multi['sex'] = LabelEncoder().fit_transform(train_multi['sex'])\n",
    "\n",
    "# Séparation des features et du label\n",
    "X_multi = train_multi.drop('smoking', axis=1)\n",
    "y_multi = train_multi['smoking']\n",
    "\n",
    "# Séparation en ensembles d'entraînement et de test\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X_multi, y_multi, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisation\n",
    "scaler_multi = StandardScaler().fit(X_train_multi)\n",
    "X_train_scaled_multi = scaler_multi.transform(X_train_multi)\n",
    "X_test_scaled_multi = scaler_multi.transform(X_test_multi)\n",
    "\n",
    "# Entraînement du modèle\n",
    "model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "model.fit(X_train_scaled_multi, y_train_multi)\n",
    "\n",
    "# Évaluation du modèle\n",
    "y_pred = model.predict(X_test_scaled_multi)\n",
    "print('Accuracy:', accuracy_score(y_test_multi, y_pred))\n",
    "print('Precision:', precision_score(y_test_multi, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test_multi, y_pred, average='weighted'))\n",
    "print('F1 Score:', f1_score(y_test_multi, y_pred, average='weighted'))\n",
    "\n",
    "# Prédiction pour le patient spécifique \n",
    "\n",
    "# probleme pour transformer M -> 0 et F -> 1\n",
    "patient_df = {\n",
    "    'age': [60],\n",
    "    'sex': ['M'],\n",
    "    'height(cm)': [160],\n",
    "    'weight(kg)': [65],\n",
    "    'waist(cm)': [78.0],\n",
    "    'eyesight(left)': [0.8],\n",
    "    'eyesight(right)': [0.7],\n",
    "    'hearing(left)': [1],\n",
    "    'hearing(right)': [1],\n",
    "    'systolic': [118],\n",
    "    'relaxation': [62],\n",
    "    'fasting blood sugar': [97],\n",
    "    'Cholesterol': [154],\n",
    "    'triglyceride': [88],\n",
    "    'HDL': [37],\n",
    "    'LDL': [100],\n",
    "    'hemoglobin': [12.6],\n",
    "    'Urine protein': [1],\n",
    "    'serum creatinine': [0.5],\n",
    "    'AST': [23],\n",
    "    'ALT': [14],\n",
    "    'Gtp': [9],\n",
    "    'dental caries': [0]\n",
    "}\n",
    "le_sex = LabelEncoder()\n",
    "le_sex.fit_transform(train_multi['sex'])\n",
    "\n",
    "patient_df = pd.DataFrame.from_dict(patient_df)\n",
    "patient_df['sex'] = le_sex.transform(patient_df['sex'])\n",
    "patient_scaled = scaler_multi.transform(patient_df)\n",
    "patient_prediction = model.predict(patient_scaled)\n",
    "# Affichage de la prédiction\n",
    "statut_tabagique = ['non fumeur', 'plutôt fumeur', 'certainement fumeur']\n",
    "print(\"Statut tabagique prédit pour le patient:\", statut_tabagique[patient_prediction[0]])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:55:33.002820900Z",
     "start_time": "2023-11-23T09:55:30.176020Z"
    }
   },
   "id": "69c1effa8a6d70a4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "def fit_and_score(models, X_train, y_train, X_test, y_test):\n",
    "    model_scores = {}\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        model_scores[model.__class__.__name__] = {\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "            'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "            'F1 Score': f1_score(y_test, y_pred, average='weighted')\n",
    "        }\n",
    "    return model_scores\n",
    "\n",
    "# Initialisation des modèles multi-classes\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    SVC(probability=True),\n",
    "    GradientBoostingClassifier(n_estimators=100),\n",
    "    MLPClassifier(max_iter=1000),\n",
    "    LogisticRegression(max_iter=1000, multi_class='ovr'),\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    "    AdaBoostClassifier(n_estimators=100)\n",
    "]\n",
    "\n",
    "# Entraînement et évaluation des modèles\n",
    "model_scores = fit_and_score(models, X_train_scaled_multi, y_train_multi, X_test_scaled_multi, y_test_multi)\n",
    "\n",
    "# Sélectionner le modèle avec le meilleur score (par exemple, F1 Score)\n",
    "best_model_name = max(model_scores, key=lambda k: model_scores[k]['F1 Score'])\n",
    "best_model = [model for model in models if model.__class__.__name__ == best_model_name][0]\n",
    "\n",
    "# Utiliser le meilleur modèle pour la prédiction du patient spécifique\n",
    "best_model.fit(X_train_scaled_multi, y_train_multi)\n",
    "patient_prediction = best_model.predict(patient_scaled)\n",
    "print(\"Statut tabagique prédit pour le patient:\", statut_tabagique[patient_prediction[0]])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:50:55.544455400Z",
     "start_time": "2023-11-23T09:50:55.542456700Z"
    }
   },
   "id": "f2d1749ec74889fb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
