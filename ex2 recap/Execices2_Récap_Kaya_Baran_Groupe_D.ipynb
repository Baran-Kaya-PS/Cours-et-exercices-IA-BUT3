{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46cdf82a-c841-4360-abdb-7a62e3bdb556",
   "metadata": {},
   "source": [
    "#### TP 4 - Exercice Récap \n",
    "Les algos d'apprentissage, régression ou classification, se basent sur plusieurs paramètres pour réaliser l'entrainement.  On y trouve en particulier\n",
    "- le type de penality : L1, L2, ... pour répondre au problème d'overfitting\n",
    "- le nombre d'itérations : max_iter , le nombre de fois que l'on fait passer les exemples\n",
    "- le solver :  optimiseur, le type d'algo utilisé pour modifier les paramètres, gradient descent (par exemple)\n",
    "\n",
    "Ces paramètres peuvent être explicìtés dans le modèle, par exemple la <span style=\"color:green\">LogisticRegression</span>\n",
    "\n",
    "```class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)```\n",
    "\n",
    "ou encore\n",
    "```class sklearn.linear_model.Ridge(alpha=1.0, *, fit_intercept=True, copy_X=True, max_iter=None, tol=0.0001, solver='auto', positive=False, random_state=None)```\n",
    " \n",
    " mais pas dans le modèle <span style=\"color:green\"> LinearRegression </span>\n",
    " \n",
    " ```class sklearn.linear_model.LinearRegression(*, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)``` ne possède pas explictement ces paramètres on les trouve par contre dans la classe ```linear_model.Ridge```\n",
    "\n",
    "Les détails sont sur : [Scikit-learn](https://scikit-learn.org/stable/index.html). \n",
    "\n",
    "Plusieurs de ces hyperparamètres sont fixés par défaut. On s'intresse à trois d'entre eux dans le cadre de ce TP: la Panalité, le nombre d'itérations.\n",
    "\n",
    "- 1) Ecrire le code qui permet de réaliser une régression logistique sur les données du dataset iris, en prenant les conditions (hyperparamètres/options) suivantes\n",
    " - cas 1 : penalité: L2 et max_iter:100  et le solver : lbfgs\n",
    " - cas 2 : penalité: L1 et max_iter:1000  et le solver : liblinear\n",
    " \n",
    "- 2) Ecrire le code d'une régression linaire sur les données houses, en prenant les conditions suivantes :\n",
    "- pénalité : L1, max_iter:1000, et solver : auto\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9733333333333334"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cas 1 pénalité L2 et max_iter 100 et solver lbfgs\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "X = (X - X.mean(axis=0))/X.std(axis=0) # normalisation pour avoir de plus petites valeurs\n",
    "y = iris.target\n",
    "clf = LogisticRegression(penalty='l2', max_iter=100, solver='lbfgs') # classifieur\n",
    "clf.fit(X, y) # entrainement\n",
    "clf.predict(X) # prédiction sur les données d'entrainement\n",
    "clf.predict_proba(X) # probabilité d'appartenance à chaque classe\n",
    "clf.score(X, y) # score de prédiction\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T10:28:41.484213800Z",
     "start_time": "2023-10-06T10:28:41.019087400Z"
    }
   },
   "id": "cb53330fbf365ed9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "0.94"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cas 2 pénalité L1 et max_iter 1000 et solver\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "X = (X - X.mean(axis=0))/X.std(axis=0) # normalisation pour avoir de plus petites valeurs\n",
    "y = iris.target\n",
    "clf = LogisticRegression(penalty='l1', max_iter=1000, solver='liblinear') # classifieur\n",
    "clf.fit(X, y) # entrainement\n",
    "clf.predict(X) # prédiction sur les données d'entrainement\n",
    "clf.predict_proba(X) # probabilité d'appartenance à chaque classe\n",
    "clf.score(X,y) # score de prédiction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T10:28:41.618927600Z",
     "start_time": "2023-10-06T10:28:41.483210900Z"
    }
   },
   "id": "cbfeecd05b41d875"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#aide pour l'exercice : https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T10:28:41.618927600Z",
     "start_time": "2023-10-06T10:28:41.518213500Z"
    }
   },
   "id": "8653f76554da3de5"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/houses.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_23400\\1173664241.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear_model\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLinearRegression\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'data/houses.txt'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msep\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m','\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mheader\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'superficie'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'nb chambre'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'étage'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'age'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'prix'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    676\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    677\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 678\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    679\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    680\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 575\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    576\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    577\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    930\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    931\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 932\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    933\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    934\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1214\u001B[0m             \u001B[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1215\u001B[0m             \u001B[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1216\u001B[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001B[0m\u001B[0;32m   1217\u001B[0m                 \u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1218\u001B[0m                 \u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    784\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;34m\"b\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    785\u001B[0m             \u001B[1;31m# Encoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 786\u001B[1;33m             handle = open(\n\u001B[0m\u001B[0;32m    787\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    788\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/houses.txt'"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "data = pd.read_csv('data/houses.txt', sep=',',header=None)\n",
    "data.head()\n",
    "data.columns = ['superficie','nb chambre','étage','age','prix']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T10:28:41.979763700Z",
     "start_time": "2023-10-06T10:28:41.531212200Z"
    }
   },
   "id": "38f81faab1d2e506"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "# cas 1 pénalité L1 et max_iter 1000 et solver auto\n",
    "x_train = data [['superficie','nb chambre','étage','age']]\n",
    "y_train = data ['prix']\n",
    "X_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3, random_state=42)\n",
    "clf = Ridge(alpha=1.0, fit_intercept=True, copy_X=True, max_iter=1000, tol=0.0001, solver='auto', positive=False, random_state=None) # classifieur\n",
    "clf.fit(X, y) # entrainement\n",
    "clf.predict(X) # prédiction sur les données d'entrainement\n",
    "clf.score(X, y) # score de prédiction soit a quel point les prédictions sont proches des valeurs réelles de 0 à 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T10:28:41.982988200Z",
     "start_time": "2023-10-06T10:28:41.981988400Z"
    }
   },
   "id": "ffa9d5b64f2c066e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#analyse des résidus\n",
    "y_pred = clf.predict(X)\n",
    "residus = y - y_pred # les résidus représente la différence entre la valeur réelle et la valeur prédite\n",
    "plt.scatter(y_pred, residus) # on trace les résidus en fonction des valeurs prédites\n",
    "plt.show() # on voit que les résidus sont répartis de manière aléatoire autour de 0 sur l'axe des y ce qui est bon signe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T10:28:41.984987400Z",
     "start_time": "2023-10-06T10:28:41.983987200Z"
    }
   },
   "id": "a02e47177251a71a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# analyse avec sns \n",
    "import seaborn as sns\n",
    "sns.residplot(y_pred, residus, lowess=True, color=\"g\") # on voit que les résidus sont répartis de manière aléatoire autour de 0 sur l'axe des y ce qui est bon signe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T10:28:41.986863200Z",
     "start_time": "2023-10-06T10:28:41.986863200Z"
    }
   },
   "id": "2500d787b81cd637"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# utilisation de Lasso pour L1 \n",
    "clf = Lasso(alpha=1.0, fit_intercept=True, copy_X=True, max_iter=1000, tol=0.0001, positive=False, random_state=None) # classifieur\n",
    "clf.fit(X, y) # entrainement\n",
    "clf.predict(X) # prédiction sur les données d'entrainement\n",
    "clf.score(X, y) # score de prédiction soit a quel point les prédictions sont proches des valeurs réelles de 0 à 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-06T10:28:41.989055200Z"
    }
   },
   "id": "d34f0bad971bd471"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#analyse des résidus\n",
    "y_pred = clf.predict(X)\n",
    "residus = y - y_pred # les résidus représente la différence entre la valeur réelle et la valeur prédite\n",
    "plt.scatter(y_pred, residus) # on trace les résidus en fonction des valeurs prédites\n",
    "plt.show()\n",
    "sns.residplot(y_pred, residus, lowess=True, color=\"g\") "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-06T10:28:41.992545300Z"
    }
   },
   "id": "9ccf1d9e3a15e16d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" lasso n'est pas très parlant \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T10:28:42.000230400Z",
     "start_time": "2023-10-06T10:28:41.995558900Z"
    }
   },
   "id": "dbaf65adf077eeb2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" notes à moi même \n",
    "\n",
    "Importer les bons modèles linéaires (regression linéaire pour faire une régression linéaire, lasso pour faire une régression lasso, ridge pour faire une régression ridge)\n",
    "\n",
    "préparer les données\n",
    "X = data[['feature1', 'feature2', ...]]\n",
    "y = data['target']\n",
    "\n",
    "divisions des données en train et test pour faire de la cross validation ce qui signifie que l'on va entrainer le modèle sur une partie des données et le tester sur une autre partie des données, ici je ne l'ai pas fait mais c'est une bonne pratique comme la normalisation des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "ne pas oublier de normaliser, la formule : \n",
    "X = (X - X.mean(axis=0))/X.std(axis=0) # X - X.moyenne / X.ecart type, axis 0 pour normaliser par colonne\n",
    "\n",
    "définition du model \n",
    "\n",
    "model = LinearRegression() # pour une régression linéaire\n",
    "model.fit(x,y) # entrainement du modèle\n",
    "model.score(x,y) # score de prédiction soit a quel point les prédictions sont proches des valeurs réelles de 0 à 1 pour vérifier si le modele est fiable\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-06T10:28:41.999218300Z"
    }
   },
   "id": "18de0242d92e1e0b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T10:28:42.088332700Z",
     "start_time": "2023-10-06T10:28:42.001231100Z"
    }
   },
   "id": "95869eb40ab578dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot avec x_test et y_test\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d98d3edfee6db59"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
